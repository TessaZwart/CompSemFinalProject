{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0afe46a0",
   "metadata": {},
   "source": [
    "# Read in Data (ENGLISH DATA first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51843a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40214e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 7745 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.en.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb83442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 1052 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.en.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347522a",
   "metadata": {},
   "source": [
    "# Baseline TNT tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eff805",
   "metadata": {},
   "source": [
    "## ENGLISH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c940b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing tagger\n",
    "tnt_tagging = tnt.TnT()\n",
    "  \n",
    "# training\n",
    "tnt_tagging.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1de9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating\n",
    "prediction = tnt_tagging.tagdata(test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa05d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of predictions \n",
    "tag_pred = []\n",
    "for i in range(0,len(prediction)):\n",
    "    for j in range (0, len(prediction[i])):\n",
    "        tag_pred.append(prediction[i][j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a78682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of real tags\n",
    "tag_real = []\n",
    "for i in range(0, len(test_tags)):\n",
    "    for j in range(0,len(test_tags[i])):\n",
    "        tag_real.append(test_tags[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b19b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6112 out of 6816 semantic tags are correct.\n",
      "We have a accuracy of 0.8967136150234741\n"
     ]
    }
   ],
   "source": [
    "#Compare and compute accuracy\n",
    "correct = 0\n",
    "for i in range(0,len(tag_real)):\n",
    "    if tag_real[i] == tag_pred[i]:\n",
    "        correct+=1\n",
    "print(correct, \"out of\", len(tag_real), \"semantic tags are correct.\")\n",
    "print(\"We have a accuracy of\", (correct/len(tag_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c73727",
   "metadata": {},
   "source": [
    "## GERMAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809b471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 1740 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.de.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b2b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 546 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.de.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d646cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516 out of 3227 semantic tags are correct.\n",
      "We have a accuracy of 0.7796715215370313\n"
     ]
    }
   ],
   "source": [
    "# initializing tagger\n",
    "tnt_tagging = tnt.TnT()\n",
    "# training\n",
    "tnt_tagging.train(train_data)\n",
    "# evaluating\n",
    "prediction = tnt_tagging.tagdata(test_token)\n",
    "\n",
    "# get the list of predictions \n",
    "tag_pred = []\n",
    "for i in range(0,len(prediction)):\n",
    "    for j in range (0, len(prediction[i])):\n",
    "        tag_pred.append(prediction[i][j][1])\n",
    "        \n",
    "# get the list of real tags\n",
    "tag_real = []\n",
    "for i in range(0, len(test_tags)):\n",
    "    for j in range(0,len(test_tags[i])):\n",
    "        tag_real.append(test_tags[i][j])\n",
    "\n",
    "#Compare and compute accuracy\n",
    "correct = 0\n",
    "for i in range(0,len(tag_real)):\n",
    "    if tag_real[i] == tag_pred[i]:\n",
    "        correct+=1\n",
    "print(correct, \"out of\", len(tag_real), \"semantic tags are correct.\")\n",
    "print(\"We have a accuracy of\", (correct/len(tag_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2dfde",
   "metadata": {},
   "source": [
    "## DUTCH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4658b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 538 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd7deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 490 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f7b93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117 out of 3059 semantic tags are correct.\n",
      "We have a accuracy of 0.692056227525335\n"
     ]
    }
   ],
   "source": [
    "# initializing tagger\n",
    "tnt_tagging = tnt.TnT()\n",
    "# training\n",
    "tnt_tagging.train(train_data)\n",
    "# evaluating\n",
    "prediction = tnt_tagging.tagdata(test_token)\n",
    "\n",
    "# get the list of predictions \n",
    "tag_pred = []\n",
    "for i in range(0,len(prediction)):\n",
    "    for j in range (0, len(prediction[i])):\n",
    "        tag_pred.append(prediction[i][j][1])\n",
    "        \n",
    "# get the list of real tags\n",
    "tag_real = []\n",
    "for i in range(0, len(test_tags)):\n",
    "    for j in range(0,len(test_tags[i])):\n",
    "        tag_real.append(test_tags[i][j])\n",
    "\n",
    "#Compare and compute accuracy\n",
    "correct = 0\n",
    "for i in range(0,len(tag_real)):\n",
    "    if tag_real[i] == tag_pred[i]:\n",
    "        correct+=1\n",
    "print(correct, \"out of\", len(tag_real), \"semantic tags are correct.\")\n",
    "print(\"We have a accuracy of\", (correct/len(tag_real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f06f1",
   "metadata": {},
   "source": [
    "## ITALIAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2adceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 684 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f542175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 460 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f912960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1807 out of 2523 semantic tags are correct.\n",
      "We have a accuracy of 0.7162108600871978\n"
     ]
    }
   ],
   "source": [
    "# initializing tagger\n",
    "tnt_tagging = tnt.TnT()\n",
    "# training\n",
    "tnt_tagging.train(train_data)\n",
    "# evaluating\n",
    "prediction = tnt_tagging.tagdata(test_token)\n",
    "\n",
    "# get the list of predictions \n",
    "tag_pred = []\n",
    "for i in range(0,len(prediction)):\n",
    "    for j in range (0, len(prediction[i])):\n",
    "        tag_pred.append(prediction[i][j][1])\n",
    "        \n",
    "# get the list of real tags\n",
    "tag_real = []\n",
    "for i in range(0, len(test_tags)):\n",
    "    for j in range(0,len(test_tags[i])):\n",
    "        tag_real.append(test_tags[i][j])\n",
    "\n",
    "#Compare and compute accuracy\n",
    "correct = 0\n",
    "for i in range(0,len(tag_real)):\n",
    "    if tag_real[i] == tag_pred[i]:\n",
    "        correct+=1\n",
    "print(correct, \"out of\", len(tag_real), \"semantic tags are correct.\")\n",
    "print(\"We have a accuracy of\", (correct/len(tag_real)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0a68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianbehrendt/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-01 10:50:47.128175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "import numpy as np \n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import DataCollatorForTokenClassification \n",
    "from transformers import AutoModelForTokenClassification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# https://github.com/rohan-paul/MachineLearning-DeepLearning-Code-for-my-YouTube-Channel/blob/master/NLP/YT_Fine_tuning_BERT_NER_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fd4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 538 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79624cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 490 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8393d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64bda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = np.load('universal_dict.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649a7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_ints(data,mydict):\n",
    "    for sentences in range(0,len(data)):\n",
    "        sent = data[sentences]\n",
    "        for i in range(0,len(sent)):\n",
    "            word = sent[i]\n",
    "            transformation = mydict[word]\n",
    "            sent[i] = transformation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c302d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags_transformed = train_tags\n",
    "test_tags_transformed = test_tags\n",
    "\n",
    "transformed_input_train = transform_into_ints(train_tags_transformed,mydict)\n",
    "transformed_input_test = transform_into_ints(test_tags_transformed,mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8db6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         train_token, transformed_input_train, test_size=0.3, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce65371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({13: 362, 1: 298, 9: 222, 21: 178, 23: 138, 6: 124, 18: 110, 2: 102, 5: 97, 12: 87, 0: 67, 4: 54, 7: 45, 20: 43, 34: 41, 11: 38, 19: 36, 29: 34, 26: 33, 31: 29, 24: 20, 38: 15, 14: 13, 16: 11, 17: 11, 39: 11, 43: 10, 53: 8, 49: 7, 8: 7, 37: 7, 22: 6, 63: 5, 41: 5, 10: 5, 27: 4, 62: 4, 35: 3, 15: 3, 42: 3, 52: 3, 33: 3, 48: 3, 47: 3, 51: 2, 25: 2, 44: 2, 55: 2, 45: 2, 54: 1, 40: 1, 58: 1, 64: 1, 50: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "D = y_train\n",
    "\n",
    "# Flatten the nested list\n",
    "flattened_list = [item for sublist in D for item in sublist]\n",
    "\n",
    "# Count the frequencies of each value\n",
    "counter = Counter(flattened_list)\n",
    "\n",
    "# Print the frequencies of each value\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3b655fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {13: 362, 1: 298, 9: 222, 21: 178, 23: 138, 6: 124, 18: 110, 2: 102, 5: 97, 12: 87, 0: 67, 4: 54, 7: 45, 20: 43, 34: 41, 11: 38, 19: 36, 29: 34, 26: 33, 31: 29, 24: 20, 38: 15, 14: 13, 16: 11, 17: 11, 39: 11, 43: 10, 53: 8, 49: 7, 8: 7, 37: 7, 22: 6, 63: 5, 41: 5, 10: 5, 27: 4, 62: 4, 35: 3, 15: 3, 42: 3, 52: 3, 33: 3, 48: 3, 47: 3, 51: 2, 25: 2, 44: 2, 55: 2, 45: 2, 54: 1, 40: 1, 58: 1, 64: 1, 50: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0394c4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(keys, values)\n",
    "plt.xlabel(\"Label\",fontsize=18)\n",
    "plt.ylabel(\"Frequeny\",fontsize=18)\n",
    "plt.title(\"Label frequency in Dutch Train Data\",fontsize=20,pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7480bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(tokens, tags):\n",
    "    ids = []\n",
    "    token = []\n",
    "    ner_tags = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        ids.append(i)\n",
    "        token.append(tokens[i])\n",
    "        ner_tags.append(tags[i])\n",
    "    return ids, token, ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b66ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get it into the correct form: https://huggingface.co/docs/datasets/v1.1.1/loading_datasets.html\n",
    "\n",
    "ids_train, tokens_train, ner_tags_train = get_ids(X_train, y_train)\n",
    "ids_val, tokens_val, ner_tags_val = get_ids(X_val, y_val)\n",
    "\n",
    "ids_test, tokens_test, ner_tags_test = get_ids(test_token, transformed_input_test)\n",
    "\n",
    "train = {'input_ids': ids_train,\n",
    "            'tokens': tokens_train,\n",
    "            'ner_tags': ner_tags_train}\n",
    "\n",
    "validation = {'input_ids': ids_val,\n",
    "            'tokens': tokens_val,\n",
    "            'ner_tags': ner_tags_val}\n",
    "\n",
    "test = {'input_ids': ids_test,\n",
    "            'tokens': tokens_test,\n",
    "            'ner_tags': ner_tags_test}\n",
    "\n",
    "train = Dataset.from_dict(train) \n",
    "validation = Dataset.from_dict(validation)\n",
    "test = Dataset.from_dict(test)\n",
    "\n",
    "data = {'train': train,\n",
    "            'validation': validation,\n",
    "            'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58347bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/julianbehrendt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 178.94it/s]\n"
     ]
    }
   ],
   "source": [
    "conll2003 = datasets.load_dataset(\"conll2003\") \n",
    "conll2003\n",
    "\n",
    "conll2003['train'] = data['train']\n",
    "conll2003['validation'] = data['validation']\n",
    "conll2003['test'] = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0c5f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 376\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 162\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2605104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True): \n",
    "\n",
    "    \n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n",
    "\n",
    "    \n",
    "    labels = [] \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]): \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        \n",
    "        previous_word_idx = None \n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None \n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        \n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                # set –100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token                 \n",
    "                label_ids.append(label[word_idx]) \n",
    "            else: \n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "                # mask the subword representations after the first subword\n",
    "                 \n",
    "            previous_word_idx = word_idx \n",
    "        labels.append(label_ids) \n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcbac28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.86ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.65ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.88ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae44961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels= 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cdfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "args = TrainingArguments( \n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\", \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32, \n",
    "    num_train_epochs=10, \n",
    "    weight_decay=0.01, \n",
    "    eval_steps = 100,  \n",
    "    save_total_limit = 2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36830b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c63d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = datasets.load_metric(\"seqeval\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0caf3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): \n",
    "    pred_logits, labels = eval_preds \n",
    "    \n",
    "    pred_logits = np.argmax(pred_logits, axis=2) \n",
    "    print(pred_logits)\n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we don’t need to apply the softmax\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for i in range(len(pred_logits)):\n",
    "        pred_seq = []\n",
    "        true_seq = []\n",
    "        for j in range(len(pred_logits[i])):\n",
    "            if labels[i][j] != -100:\n",
    "                pred_seq.append(pred_logits[i][j])\n",
    "                true_seq.append(labels[i][j])\n",
    "        predictions.append(pred_seq)\n",
    "        true_labels.append(true_seq)\n",
    "    \n",
    "    results = metric.compute(predictions=predictions, references=true_labels) \n",
    "    return { \n",
    "   \"precision\": results[\"overall_precision\"], \n",
    "   \"recall\": results[\"overall_recall\"], \n",
    "   \"f1\": results[\"overall_f1\"], \n",
    "  \"accuracy\": results[\"overall_accuracy\"], \n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfb4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( \n",
    "    model, \n",
    "    args, \n",
    "   train_dataset=tokenized_datasets[\"train\"], \n",
    "   eval_dataset=tokenized_datasets[\"validation\"], \n",
    "   data_collator=data_collator, \n",
    "   tokenizer=tokenizer, \n",
    "   compute_metrics=compute_metrics \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7140ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 376\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 120\n",
      "  Number of trainable parameters = 108944709\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 69/120 02:44 < 02:05, 0.41 it/s, Epoch 5.67/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872045</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.585071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872045</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.585071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872045</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.585071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872045</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.585071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.872045</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.585071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 162\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  6 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]\n",
      " [13  9  9 ...  0  0  0]\n",
      " ...\n",
      " [13  5  5 ...  5  5  0]\n",
      " [13  9  2 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 162\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  6 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]\n",
      " [13  9  9 ...  0  0  0]\n",
      " ...\n",
      " [13  5  5 ...  5  5  0]\n",
      " [13  9  2 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 162\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  6 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]\n",
      " [13  9  9 ...  0  0  0]\n",
      " ...\n",
      " [13  5  5 ...  5  5  0]\n",
      " [13  9  2 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 162\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  6 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]\n",
      " [13  9  9 ...  0  0  0]\n",
      " ...\n",
      " [13  5  5 ...  5  5  0]\n",
      " [13  9  2 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 162\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  6 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]\n",
      " [13  9  9 ...  0  0  0]\n",
      " ...\n",
      " [13  5  5 ...  5  5  0]\n",
      " [13  9  2 ...  0  0  0]\n",
      " [13  5  5 ...  0  0  0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/transformers/trainer.py:2557\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2555\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2557\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce72fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in bert_nl/config.json\n",
      "Model weights saved in bert_nl/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_nl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f8a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file bert_nl/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert_nl\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file bert_nl/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at bert_nl.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_fine_tuned_nl = AutoModelForTokenClassification.from_pretrained(\"bert_nl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a96abd",
   "metadata": {},
   "source": [
    "# Prediction of Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61547883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "len_test = 490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3a2454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"ner\", model= model_fine_tuned_nl, tokenizer=tokenizer)\n",
    "\n",
    "all_true_labels = []\n",
    "all_prediction_labels = []\n",
    "for i in range(0,len_test):\n",
    "    test_data = conll2003['test'][i] \n",
    "    \n",
    "    true_labels = test_data['ner_tags']\n",
    "    all_true_labels.append(true_labels)\n",
    "    \n",
    "    tokens = test_data['tokens']\n",
    "    ner_predictions = nlp(tokens)\n",
    "    \n",
    "    prediction_labels = []\n",
    "    for i in range(0, len(ner_predictions)):\n",
    "        x = ner_predictions[i]\n",
    "        s = x[0]\n",
    "        string = s['entity']\n",
    "        label = int(re.search(r'\\d+', string).group())\n",
    "        prediction_labels.append(label)\n",
    "    \n",
    "    \n",
    "    all_prediction_labels.append(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "581df158",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=all_prediction_labels, references=all_true_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b21a7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201046093494606"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_labels_as_array = []\n",
    "for i in range(0, len(all_true_labels)):\n",
    "    sentence_labels = all_true_labels[i]\n",
    "    for j in range(0,len(sentence_labels)):\n",
    "        all_true_labels_as_array.append(sentence_labels[j])\n",
    "\n",
    "all_predicted_labels_as_array = []\n",
    "for i in range(0, len(all_prediction_labels)):\n",
    "    sentence_labels = all_prediction_labels[i]\n",
    "    for j in range(0,len(sentence_labels)):\n",
    "        all_predicted_labels_as_array.append(sentence_labels[j])\n",
    "        \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(all_true_labels_as_array,all_predicted_labels_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fc2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

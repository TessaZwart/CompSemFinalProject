{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0a68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianbehrendt/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-31 18:07:53.302724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "import numpy as np \n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import DataCollatorForTokenClassification \n",
    "from transformers import AutoModelForTokenClassification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# https://github.com/rohan-paul/MachineLearning-DeepLearning-Code-for-my-YouTube-Channel/blob/master/NLP/YT_Fine_tuning_BERT_NER_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fd4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data set has 684 sentences.\n"
     ]
    }
   ],
   "source": [
    "# This code block reads the data.txt file and outputs a list of lists with the tokens and\n",
    "# a list of list of the semantic tags\n",
    "\n",
    "full_sen = []\n",
    "with open('train.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The training data set has\",len(train_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79624cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 460 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8393d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649a7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_ints(data,mydict):\n",
    "    for sentences in range(0,len(data)):\n",
    "        sent = data[sentences]\n",
    "        for i in range(0,len(sent)):\n",
    "            word = sent[i]\n",
    "            transformation = mydict[word]\n",
    "            sent[i] = transformation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d522bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = np.load('universal_dict.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c302d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags_transformed = train_tags\n",
    "test_tags_transformed = test_tags\n",
    "\n",
    "transformed_input_train = transform_into_ints(train_tags_transformed,mydict)\n",
    "transformed_input_test = transform_into_ints(test_tags_transformed,mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8db6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         train_token, transformed_input_train, test_size=0.3, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce65371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({13: 458, 1: 276, 2: 239, 5: 222, 23: 181, 12: 129, 6: 112, 9: 111, 21: 107, 0: 89, 18: 85, 29: 78, 7: 54, 3: 44, 34: 37, 26: 35, 20: 34, 19: 34, 31: 31, 39: 30, 11: 28, 4: 26, 14: 23, 24: 21, 15: 16, 30: 15, 43: 14, 16: 12, 41: 11, 22: 10, 38: 10, 17: 9, 53: 9, 37: 7, 62: 7, 35: 6, 50: 6, 25: 5, 44: 4, 49: 4, 10: 4, 42: 4, 45: 3, 28: 2, 33: 2, 32: 2, 52: 2, 58: 2, 40: 1, 48: 1, 47: 1, 59: 1, 54: 1, 8: 1, 55: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "D = y_train\n",
    "\n",
    "# Flatten the nested list\n",
    "flattened_list = [item for sublist in D for item in sublist]\n",
    "\n",
    "# Count the frequencies of each value\n",
    "counter = Counter(flattened_list)\n",
    "\n",
    "# Print the frequencies of each value\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7480bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(tokens, tags):\n",
    "    ids = []\n",
    "    token = []\n",
    "    ner_tags = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        ids.append(i)\n",
    "        token.append(tokens[i])\n",
    "        ner_tags.append(tags[i])\n",
    "    return ids, token, ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b66ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get it into the correct form: https://huggingface.co/docs/datasets/v1.1.1/loading_datasets.html\n",
    "\n",
    "ids_train, tokens_train, ner_tags_train = get_ids(X_train, y_train)\n",
    "ids_val, tokens_val, ner_tags_val = get_ids(X_val, y_val)\n",
    "\n",
    "ids_test, tokens_test, ner_tags_test = get_ids(test_token, transformed_input_test)\n",
    "\n",
    "train = {'input_ids': ids_train,\n",
    "            'tokens': tokens_train,\n",
    "            'ner_tags': ner_tags_train}\n",
    "\n",
    "validation = {'input_ids': ids_val,\n",
    "            'tokens': tokens_val,\n",
    "            'ner_tags': ner_tags_val}\n",
    "\n",
    "test = {'input_ids': ids_test,\n",
    "            'tokens': tokens_test,\n",
    "            'ner_tags': ner_tags_test}\n",
    "\n",
    "train = Dataset.from_dict(train) \n",
    "validation = Dataset.from_dict(validation)\n",
    "test = Dataset.from_dict(test)\n",
    "\n",
    "data = {'train': train,\n",
    "            'validation': validation,\n",
    "            'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58347bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/julianbehrendt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 214.82it/s]\n"
     ]
    }
   ],
   "source": [
    "conll2003 = datasets.load_dataset(\"conll2003\") \n",
    "conll2003\n",
    "\n",
    "conll2003['train'] = data['train']\n",
    "conll2003['validation'] = data['validation']\n",
    "conll2003['test'] = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0c5f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 478\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 206\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 460\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2605104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True): \n",
    "\n",
    "    \n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n",
    "\n",
    "    \n",
    "    labels = [] \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]): \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        \n",
    "        previous_word_idx = None \n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None \n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        \n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                # set –100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token                 \n",
    "                label_ids.append(label[word_idx]) \n",
    "            else: \n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "                # mask the subword representations after the first subword\n",
    "                 \n",
    "            previous_word_idx = word_idx \n",
    "        labels.append(label_ids) \n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcbac28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.92ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 35.58ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.74ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae44961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels= 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cdfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "args = TrainingArguments( \n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\", \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32, \n",
    "    num_train_epochs=10, \n",
    "    weight_decay=0.01, \n",
    "    eval_steps = 100,  \n",
    "    save_total_limit = 2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36830b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c63d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = datasets.load_metric(\"seqeval\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0caf3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): \n",
    "    pred_logits, labels = eval_preds \n",
    "    \n",
    "    pred_logits = np.argmax(pred_logits, axis=2) \n",
    "    \n",
    "    # print(pred_logits)\n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we don’t need to apply the softmax\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for i in range(len(pred_logits)):\n",
    "        pred_seq = []\n",
    "        true_seq = []\n",
    "        for j in range(len(pred_logits[i])):\n",
    "            if labels[i][j] != -100:\n",
    "                pred_seq.append(pred_logits[i][j])\n",
    "                true_seq.append(labels[i][j])\n",
    "        predictions.append(pred_seq)\n",
    "        true_labels.append(true_seq)\n",
    "    \n",
    "    results = metric.compute(predictions=predictions, references=true_labels) \n",
    "    return { \n",
    "   \"precision\": results[\"overall_precision\"], \n",
    "   \"recall\": results[\"overall_recall\"], \n",
    "   \"f1\": results[\"overall_f1\"], \n",
    "  \"accuracy\": results[\"overall_accuracy\"], \n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cfb4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( \n",
    "    model, \n",
    "    args, \n",
    "   train_dataset=tokenized_datasets[\"train\"], \n",
    "   eval_dataset=tokenized_datasets[\"validation\"], \n",
    "   data_collator=data_collator, \n",
    "   tokenizer=tokenizer, \n",
    "   compute_metrics=compute_metrics \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7140ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 478\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 108944709\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 10:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.084930</td>\n",
       "      <td>0.437220</td>\n",
       "      <td>0.203975</td>\n",
       "      <td>0.278174</td>\n",
       "      <td>0.290909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.592833</td>\n",
       "      <td>0.485666</td>\n",
       "      <td>0.301255</td>\n",
       "      <td>0.371853</td>\n",
       "      <td>0.392929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.258598</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.364017</td>\n",
       "      <td>0.403712</td>\n",
       "      <td>0.437879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.009289</td>\n",
       "      <td>0.472959</td>\n",
       "      <td>0.466527</td>\n",
       "      <td>0.469721</td>\n",
       "      <td>0.524242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.809215</td>\n",
       "      <td>0.524607</td>\n",
       "      <td>0.524059</td>\n",
       "      <td>0.524333</td>\n",
       "      <td>0.578788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.669311</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.570084</td>\n",
       "      <td>0.562726</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.584316</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.595188</td>\n",
       "      <td>0.579725</td>\n",
       "      <td>0.640404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.526986</td>\n",
       "      <td>0.597737</td>\n",
       "      <td>0.607741</td>\n",
       "      <td>0.602697</td>\n",
       "      <td>0.653535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.477333</td>\n",
       "      <td>0.589431</td>\n",
       "      <td>0.606695</td>\n",
       "      <td>0.597938</td>\n",
       "      <td>0.663131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.466095</td>\n",
       "      <td>0.603640</td>\n",
       "      <td>0.624477</td>\n",
       "      <td>0.613882</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 206\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=2.0924471028645835, metrics={'train_runtime': 603.7646, 'train_samples_per_second': 7.917, 'train_steps_per_second': 0.248, 'total_flos': 45579987400428.0, 'train_loss': 2.0924471028645835, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce72fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in bert_it/config.json\n",
      "Model weights saved in bert_it/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8f8a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file bert_it/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert_it\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file bert_it/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at bert_it.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_fine_tuned_italien = AutoModelForTokenClassification.from_pretrained(\"bert_it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61547883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "len_test = 460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3a2454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model= model_fine_tuned_italien, tokenizer=tokenizer)\n",
    "\n",
    "all_true_labels = []\n",
    "all_prediction_labels = []\n",
    "for i in range(0,len_test):\n",
    "    test_data = conll2003['test'][i] \n",
    "    \n",
    "    true_labels = test_data['ner_tags']\n",
    "    all_true_labels.append(true_labels)\n",
    "    \n",
    "    tokens = test_data['tokens']\n",
    "    ner_predictions = nlp(tokens)\n",
    "    \n",
    "    prediction_labels = []\n",
    "    for i in range(0, len(ner_predictions)):\n",
    "        x = ner_predictions[i]\n",
    "        s = x[0]\n",
    "        string = s['entity']\n",
    "        label = int(re.search(r'\\d+', string).group())\n",
    "        prediction_labels.append(label)\n",
    "    \n",
    "    \n",
    "    all_prediction_labels.append(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "199cb1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 5, 23, 5, 13],\n",
       " [5, 12, 5, 13, 2, 5, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [5, 5, 13, 13, 18, 13, 34],\n",
       " [5, 2, 12, 23, 23, 13],\n",
       " [5, 5, 9, 5, 13],\n",
       " [14, 2, 18, 9, 13],\n",
       " [5, 13, 2, 18, 13],\n",
       " [5, 6, 12, 13],\n",
       " [0, 1, 18, 13, 0, 18, 13],\n",
       " [23, 1, 5, 2, 1, 13],\n",
       " [9, 2, 23, 5, 9, 13],\n",
       " [2, 5, 13],\n",
       " [5, 5, 6, 13, 6, 13],\n",
       " [5, 5, 2, 12, 13],\n",
       " [9, 5, 0, 12, 13],\n",
       " [5, 1, 23, 1, 13, 14, 1, 13],\n",
       " [6, 12, 13],\n",
       " [5, 5, 23, 18, 13],\n",
       " [5, 2, 18, 5, 13],\n",
       " [5, 2, 12, 12, 13],\n",
       " [14, 2, 5, 12, 13],\n",
       " [23, 6, 1, 2, 5, 13, 5, 5, 13],\n",
       " [23, 5, 13, 5, 2, 1, 13],\n",
       " [9, 5, 23, 4, 1, 13],\n",
       " [23, 1, 5, 13],\n",
       " [5, 1, 13],\n",
       " [5, 5, 23, 5, 5, 5, 13],\n",
       " [5, 6, 13],\n",
       " [5, 2, 5, 5, 13],\n",
       " [9, 13, 5, 23, 4, 5, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [5, 6, 23, 5, 23, 5, 13],\n",
       " [5, 2, 5, 5, 13, 2, 5, 13],\n",
       " [9, 5, 13, 5, 5, 14, 1, 13],\n",
       " [23, 6, 5, 2, 6, 13],\n",
       " [9, 12, 5, 13],\n",
       " [9, 18, 13, 23, 5, 12, 13],\n",
       " [5, 18, 23, 23, 13],\n",
       " [13, 2, 6, 6, 6, 13],\n",
       " [13, 5, 5, 34],\n",
       " [5, 6, 23, 1, 13],\n",
       " [0, 2, 18, 23, 12, 13, 5, 13],\n",
       " [23, 4, 6, 13, 6, 13],\n",
       " [9, 6, 0, 5, 5, 13],\n",
       " [23, 18, 2, 9, 13],\n",
       " [23, 5, 13, 6, 2, 5, 13],\n",
       " [9, 2, 12, 13, 12, 13],\n",
       " [13, 18, 13, 13, 13],\n",
       " [9, 2, 6, 23, 5, 5, 13],\n",
       " [43, 5, 2, 0, 12, 13],\n",
       " [23, 5, 2, 12, 0, 12, 5, 23, 6, 13, 5, 13],\n",
       " [23, 6, 2, 5, 12, 13],\n",
       " [9, 5, 6, 13],\n",
       " [5, 2, 6, 13, 6, 13],\n",
       " [9, 5, 5, 13],\n",
       " [9, 6, 18, 13, 1, 13],\n",
       " [9, 2, 1, 13],\n",
       " [5, 12, 0, 6, 13],\n",
       " [5, 2, 5, 13],\n",
       " [5, 2, 12, 0, 6, 1, 5, 5, 13],\n",
       " [5, 13, 23, 4, 5, 13],\n",
       " [2, 12, 13, 43, 5, 13],\n",
       " [2, 18, 13],\n",
       " [6, 13, 2, 9, 12, 13],\n",
       " [23, 5, 6, 13],\n",
       " [2, 12, 13],\n",
       " [9, 6, 1, 13],\n",
       " [5, 2, 12, 13, 0, 34],\n",
       " [5, 6, 13],\n",
       " [6, 9, 18, 14, 1, 13],\n",
       " [9, 2, 6, 13],\n",
       " [5, 2, 5, 13],\n",
       " [2, 5, 13],\n",
       " [5, 6, 13],\n",
       " [2, 5, 13],\n",
       " [13, 2, 9, 2, 6, 5, 1, 13],\n",
       " [5, 5, 2, 6, 13],\n",
       " [2, 6, 13],\n",
       " [23, 4, 6, 1, 13],\n",
       " [5, 2, 18, 9, 5, 5, 13],\n",
       " [5, 5, 13],\n",
       " [5, 2, 6, 0, 5, 5, 5, 13],\n",
       " [5, 5, 13],\n",
       " [2, 12, 13],\n",
       " [9, 2, 6, 5, 13],\n",
       " [9, 9, 18, 0, 5, 1, 13],\n",
       " [9, 5, 6, 23, 5, 13],\n",
       " [5, 5, 2, 12, 13],\n",
       " [14, 12, 2, 6, 5, 12, 13],\n",
       " [2, 5, 13, 5, 13],\n",
       " [23, 1, 2, 5, 23, 1, 13],\n",
       " [6, 5, 13, 13],\n",
       " [5, 2, 12, 5, 1, 13],\n",
       " [14, 5, 5, 18, 1, 13],\n",
       " [23, 18, 12, 13, 13],\n",
       " [5, 5, 23, 1, 1, 13],\n",
       " [2, 12, 12, 2, 23, 6, 6, 13],\n",
       " [9, 2, 12, 13, 5, 13],\n",
       " [5, 2, 12, 5, 18, 13],\n",
       " [9, 5, 2, 6, 13, 6, 34],\n",
       " [9, 5, 13, 5, 13],\n",
       " [23, 5, 2, 6, 23, 6, 13],\n",
       " [23, 5, 6, 13],\n",
       " [5, 2, 5, 13],\n",
       " [5, 2, 0, 13, 18, 13],\n",
       " [5, 2, 5, 12, 13, 5, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 12, 9, 1, 13, 13],\n",
       " [5, 5, 9, 1, 5, 13],\n",
       " [5, 5, 6, 23, 18, 13],\n",
       " [23, 5, 12, 13, 23, 5, 13],\n",
       " [23, 5, 5, 18, 5, 13],\n",
       " [6, 9, 2, 12, 13],\n",
       " [5, 2, 6, 5, 34],\n",
       " [9, 2, 18, 23, 1, 1, 13],\n",
       " [5, 6, 23, 5, 13],\n",
       " [5, 9, 13, 5, 13],\n",
       " [5, 5, 13],\n",
       " [13, 13, 18, 13, 1, 13],\n",
       " [23, 5, 5, 5, 13],\n",
       " [5, 12, 5, 13],\n",
       " [23, 6, 5, 13],\n",
       " [5, 2, 0, 1, 12, 13],\n",
       " [5, 2, 0, 12, 1, 13],\n",
       " [0, 5, 18, 13, 12, 13],\n",
       " [9, 6, 5, 23, 1, 13],\n",
       " [23, 12, 2, 12, 13, 1, 13],\n",
       " [5, 9, 13, 5, 13, 13, 5, 13],\n",
       " [23, 5, 5, 18, 13, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [23, 6, 2, 6, 13],\n",
       " [23, 5, 5, 23, 5, 13],\n",
       " [5, 5, 6, 13, 5, 13],\n",
       " [5, 2, 5, 5, 13, 5, 13],\n",
       " [9, 5, 2, 12, 13],\n",
       " [6, 13, 23, 5, 13],\n",
       " [6, 1, 13],\n",
       " [6, 9, 1, 2, 12, 13],\n",
       " [9, 2, 6, 13],\n",
       " [23, 1, 6, 5, 13],\n",
       " [5, 2, 1, 13],\n",
       " [5, 2, 1, 13],\n",
       " [5, 5, 18, 13],\n",
       " [23, 18, 6, 6, 13],\n",
       " [14, 1, 5, 5, 5, 13, 13],\n",
       " [13, 6, 1, 13, 6, 13],\n",
       " [5, 6, 23, 12, 13],\n",
       " [5, 6, 9, 13],\n",
       " [23, 12, 2, 18, 23, 2, 1, 13, 23, 12, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [23, 5, 5, 13, 5, 13],\n",
       " [9, 18, 13],\n",
       " [2, 5],\n",
       " [5, 2, 6, 23, 18, 34],\n",
       " [5, 2, 23, 5, 13, 5, 5, 34],\n",
       " [23, 5, 5, 5, 18, 9, 13],\n",
       " [9, 6, 23, 23, 13, 23, 6, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [23, 5, 5, 6, 23, 1, 13],\n",
       " [2, 6, 13],\n",
       " [9, 5, 23, 5, 5, 9, 13],\n",
       " [5, 6, 13, 18, 23, 5, 13],\n",
       " [5, 5, 18, 2, 5, 13],\n",
       " [23, 6, 2, 3, 2, 6, 13],\n",
       " [5, 2, 18, 23, 13, 5, 13, 34],\n",
       " [6, 6, 5, 34],\n",
       " [5, 2, 12, 13],\n",
       " [9, 2, 6, 13, 5, 13],\n",
       " [12, 9, 13],\n",
       " [6, 6, 23, 6, 13],\n",
       " [9, 1, 5, 13],\n",
       " [5, 6, 43, 6, 13],\n",
       " [5, 2, 5, 12, 13, 5, 13],\n",
       " [5, 2, 5, 6, 13, 18, 13],\n",
       " [43, 5, 13, 6, 13],\n",
       " [5, 2, 5, 23, 9, 13],\n",
       " [5, 2, 6, 13],\n",
       " [23, 5, 0, 2, 5, 13],\n",
       " [5, 5, 2, 6, 13],\n",
       " [6, 9, 5, 18, 13],\n",
       " [5, 2, 12, 1, 13],\n",
       " [5, 5, 2, 5, 6, 13],\n",
       " [5, 2, 12, 13],\n",
       " [0, 2, 12, 13, 5, 34],\n",
       " [5, 2, 12, 13],\n",
       " [23, 18, 5, 13],\n",
       " [9, 9, 18, 9, 5, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 0, 13, 13],\n",
       " [5, 5, 2, 5, 12, 13],\n",
       " [5, 2, 12, 23, 1, 13],\n",
       " [5, 2, 18, 13],\n",
       " [5, 2, 12, 5, 13],\n",
       " [5, 6, 18, 13],\n",
       " [23, 18, 2, 18, 23, 18, 13],\n",
       " [9, 5, 13, 1, 13],\n",
       " [9, 9, 13, 18, 13],\n",
       " [12, 2, 18, 5, 13],\n",
       " [5, 2, 23, 5, 13],\n",
       " [5, 5, 2, 5, 5, 13],\n",
       " [2, 12, 13],\n",
       " [23, 1, 2, 1, 13],\n",
       " [9, 5, 6, 0, 6, 13],\n",
       " [23, 1, 5, 13, 1, 13],\n",
       " [5, 2, 5, 34],\n",
       " [9, 5, 2, 12, 23, 5, 13],\n",
       " [23, 5, 5, 13],\n",
       " [5, 6, 23, 5, 13],\n",
       " [5, 5, 6, 13, 0, 5, 13],\n",
       " [5, 2, 12, 13, 13, 6, 13],\n",
       " [23, 5, 2, 6, 13, 5, 13],\n",
       " [14, 5, 2, 13, 13],\n",
       " [23, 5, 13, 5, 13, 2, 12, 12, 2, 5, 13],\n",
       " [23, 5, 12, 23, 5, 13],\n",
       " [6, 2, 6, 13],\n",
       " [23, 5, 5, 13],\n",
       " [23, 18, 5, 23, 5, 13],\n",
       " [6, 13, 5, 2, 12, 13],\n",
       " [5, 2, 6, 5, 13],\n",
       " [9, 2, 12, 5, 18, 13],\n",
       " [23, 5, 5, 6, 23, 18, 13],\n",
       " [23, 5, 13, 5, 13, 2, 12, 12, 2, 5, 13],\n",
       " [5, 2, 12, 6, 5, 18, 13],\n",
       " [23, 18, 5, 23, 18, 13],\n",
       " [23, 18, 5, 2, 18, 13],\n",
       " [9, 18, 2, 5, 34],\n",
       " [18, 1, 5, 5, 34],\n",
       " [5, 5, 13],\n",
       " [5, 5, 0, 12, 13, 12, 23, 5, 13],\n",
       " [5, 6, 43, 6, 13],\n",
       " [9, 2, 6, 0, 1, 13, 12, 13],\n",
       " [5, 23, 2, 1, 13],\n",
       " [14, 2, 0, 18, 13, 1, 13],\n",
       " [5, 5, 2, 23, 6, 6, 13],\n",
       " [5, 6, 2, 12, 13],\n",
       " [23, 1, 13, 5, 2, 18, 13],\n",
       " [0, 2, 12, 6, 34],\n",
       " [13, 2, 18, 23, 2, 6, 13],\n",
       " [23, 1, 5, 23, 5, 13],\n",
       " [6, 9, 6, 5, 13],\n",
       " [9, 9, 12, 13],\n",
       " [23, 6, 2, 18, 23, 12, 13],\n",
       " [9, 1, 0, 1, 13],\n",
       " [5, 2, 12, 12, 13, 5, 13],\n",
       " [5, 6, 23, 12, 13, 5, 13],\n",
       " [5, 5, 13, 5, 13],\n",
       " [9, 5, 23, 5, 13],\n",
       " [5, 5, 23, 6, 13],\n",
       " [23, 5, 6, 6, 23, 6, 13],\n",
       " [23, 5, 5, 6, 1, 13],\n",
       " [5, 5, 2, 1, 13],\n",
       " [5, 5, 13],\n",
       " [5, 6, 0, 5, 13],\n",
       " [5, 2, 12, 12, 6, 18, 13],\n",
       " [9, 5, 5, 13],\n",
       " [2, 5, 1, 13],\n",
       " [9, 9, 5, 23, 5, 13, 5, 13],\n",
       " [23, 1, 6, 23, 5, 13],\n",
       " [23, 5, 5, 1, 23, 5, 13],\n",
       " [5, 18, 13],\n",
       " [5, 5, 2, 12, 13],\n",
       " [5, 13, 2, 12, 12, 13],\n",
       " [5, 2, 12, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 5, 13, 18, 13],\n",
       " [9, 5, 6, 13],\n",
       " [5, 5, 18, 23, 23, 13],\n",
       " [5, 2, 12, 23, 6, 13],\n",
       " [5, 6, 9, 1, 13],\n",
       " [5, 18, 5, 18, 13],\n",
       " [9, 2, 12, 5, 18, 13],\n",
       " [5, 6, 5, 13],\n",
       " [5, 6, 23, 5, 13],\n",
       " [9, 9, 12, 5, 13],\n",
       " [9, 12, 13, 5, 13],\n",
       " [13, 9, 18, 23, 6, 18, 34],\n",
       " [13, 5, 5, 34],\n",
       " [5, 6, 13],\n",
       " [9, 5, 1, 13],\n",
       " [13, 18, 13, 9, 13],\n",
       " [5, 9, 13, 13],\n",
       " [5, 2, 6, 0, 18, 5, 13],\n",
       " [23, 1, 2, 12, 23, 5, 13],\n",
       " [5, 5, 5, 1, 13],\n",
       " [5, 5, 13, 9, 13],\n",
       " [14, 18, 6, 0, 18, 13],\n",
       " [23, 5, 5, 2, 6, 13],\n",
       " [5, 2, 0, 6, 13],\n",
       " [13, 18, 6, 9, 12, 13],\n",
       " [13, 5, 5, 34],\n",
       " [14, 5, 2, 12, 13],\n",
       " [23, 6, 5, 2, 1, 13],\n",
       " [9, 6, 23, 5, 13],\n",
       " [23, 5, 12, 13],\n",
       " [23, 5, 12, 2, 5, 13],\n",
       " [23, 12, 12, 23, 5, 13],\n",
       " [9, 5, 6, 5, 5, 13],\n",
       " [5, 5, 2, 12, 13],\n",
       " [23, 1, 2, 12, 5, 5, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [5, 2, 18, 13, 5, 13],\n",
       " [23, 6, 5, 2, 12, 5, 2, 5, 13],\n",
       " [5, 2, 6, 0, 1, 13, 23, 2, 9, 13],\n",
       " [5, 2, 12, 23, 18, 13],\n",
       " [5, 5, 6, 23, 5, 13],\n",
       " [5, 2, 0, 1, 12, 13],\n",
       " [23, 5, 6, 5, 12, 13],\n",
       " [5, 2, 6, 0, 1, 13],\n",
       " [9, 5, 0, 1, 13],\n",
       " [6, 13, 9, 13, 6, 13],\n",
       " [0, 5, 5, 13],\n",
       " [5, 2, 0, 18, 12, 13],\n",
       " [5, 13, 5, 13],\n",
       " [5, 5, 12, 13, 12, 13],\n",
       " [5, 2, 23, 5, 13],\n",
       " [13, 5, 5, 34],\n",
       " [1, 0, 6, 2, 12, 13],\n",
       " [23, 1, 5, 12, 2, 23, 18, 13],\n",
       " [5, 5, 13],\n",
       " [14, 1, 13, 5, 13],\n",
       " [12, 23, 5, 13, 5, 5, 2, 12, 13],\n",
       " [5, 13, 2, 12, 13],\n",
       " [5, 2, 5, 23, 5, 13],\n",
       " [5, 5, 2, 0, 12, 13],\n",
       " [23, 5, 6, 23, 18, 13],\n",
       " [23, 12, 5, 1, 13],\n",
       " [5, 6, 0, 5, 13],\n",
       " [5, 6, 13],\n",
       " [13, 5, 6, 1, 13],\n",
       " [5, 6, 5, 13],\n",
       " [2, 6, 13],\n",
       " [23, 5, 2, 12, 12, 12, 13],\n",
       " [5, 2, 23, 1, 5, 5, 34],\n",
       " [6, 1, 2, 5, 34],\n",
       " [5, 2, 12, 23, 5, 13],\n",
       " [5, 13, 9, 2, 18, 13],\n",
       " [5, 6, 6, 13],\n",
       " [5, 2, 6, 13, 5, 13, 5, 13],\n",
       " [9, 12, 0, 12, 13],\n",
       " [5, 2, 5, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [5, 18, 13],\n",
       " [23, 18, 6, 13],\n",
       " [5, 2, 6, 13],\n",
       " [9, 5, 9, 13, 6, 13, 5, 13],\n",
       " [9, 5, 13, 1, 13, 14, 12, 13],\n",
       " [5, 2, 5, 13],\n",
       " [9, 6, 18, 13, 1, 13],\n",
       " [0, 1, 12, 13, 6, 1, 13],\n",
       " [14, 5, 13],\n",
       " [5, 18, 5, 13, 1, 13],\n",
       " [9, 5, 2, 5, 13, 18, 13],\n",
       " [5, 2, 18, 5, 5, 13],\n",
       " [5, 5, 5, 13],\n",
       " [5, 5, 5, 5, 13],\n",
       " [5, 2, 0, 12, 13],\n",
       " [13, 5, 5, 34],\n",
       " [5, 2, 18, 6, 1, 13, 5, 13],\n",
       " [23, 5, 5, 23, 12, 18, 13],\n",
       " [5, 2, 12, 6, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [9, 9, 6, 13],\n",
       " [9, 2, 12, 5, 5, 13],\n",
       " [23, 1, 5, 13],\n",
       " [23, 1, 2, 13, 6, 5, 13],\n",
       " [5, 18, 23, 5, 5, 13],\n",
       " [5, 2, 5, 13],\n",
       " [2, 18, 13],\n",
       " [23, 18, 5, 13],\n",
       " [23, 5, 12, 13, 13, 34],\n",
       " [5, 2, 6, 13],\n",
       " [5, 6, 13],\n",
       " [9, 13, 6, 13],\n",
       " [9, 18, 23, 5, 13, 0, 5, 13],\n",
       " [23, 5, 2, 12, 13],\n",
       " [14, 1, 2, 5, 12, 13],\n",
       " [9, 5, 2, 1, 13, 6, 34],\n",
       " [5, 2, 12, 14, 1, 5, 23, 5, 13],\n",
       " [5, 12, 5, 13],\n",
       " [5, 5, 12, 23, 5, 13],\n",
       " [43, 1, 2, 6, 23, 18, 13, 5, 13],\n",
       " [9, 2, 0, 1, 13],\n",
       " [14, 18, 5, 5, 12, 5, 13],\n",
       " [5, 2, 5, 0, 18, 13],\n",
       " [5, 2, 5, 13, 6, 12, 13],\n",
       " [14, 18, 18, 13],\n",
       " [5, 5, 23, 5, 13],\n",
       " [5, 1, 13, 5, 13],\n",
       " [5, 6, 12, 13],\n",
       " [5, 6, 0, 5, 5, 5, 13],\n",
       " [9, 5, 6, 5, 1, 9, 18, 13],\n",
       " [9, 2, 0, 6, 5, 13],\n",
       " [13, 18, 18, 13, 5, 13],\n",
       " [9, 5, 23, 18, 13],\n",
       " [9, 2, 5, 23, 6, 13],\n",
       " [9, 5, 23, 5, 13],\n",
       " [23, 1, 12, 13],\n",
       " [5, 5, 13, 1, 13],\n",
       " [5, 2, 18, 12, 13],\n",
       " [14, 12, 6, 2, 5, 5, 13],\n",
       " [5, 6, 13, 5, 13],\n",
       " [23, 1, 5, 23, 5, 18, 13],\n",
       " [5, 2, 18, 23, 4, 5, 13],\n",
       " [23, 1, 6, 12, 13],\n",
       " [5, 6, 5, 13],\n",
       " [5, 2, 5, 13],\n",
       " [9, 6, 18, 0, 6, 5, 6, 13],\n",
       " [9, 6, 0, 5, 13],\n",
       " [5, 2, 18, 13],\n",
       " [5, 5, 5, 13],\n",
       " [5, 5, 2, 5, 13],\n",
       " [5, 2, 12, 13],\n",
       " [13, 5, 6, 13],\n",
       " [5, 5, 2, 5, 5, 13],\n",
       " [9, 6, 13],\n",
       " [5, 5, 6, 13, 5, 13],\n",
       " [0, 23, 2, 5, 34],\n",
       " [13, 5, 5, 34],\n",
       " [5, 2, 12, 12, 13],\n",
       " [5, 2, 12, 23, 1, 13],\n",
       " [5, 2, 18, 13],\n",
       " [5, 2, 29, 5, 5, 18, 13],\n",
       " [9, 43, 9, 6, 21, 5, 5, 18, 13],\n",
       " [5, 5, 13, 26, 13],\n",
       " [18, 5, 5, 2, 9, 5, 6, 13],\n",
       " [23, 5, 6, 6, 13],\n",
       " [5, 5, 5, 5, 13],\n",
       " [5, 5, 18, 13, 5, 13],\n",
       " [5, 2, 0, 12, 5, 13],\n",
       " [23, 5, 6, 13, 1, 13],\n",
       " [13, 5, 5, 34],\n",
       " [9, 29, 0, 1, 5, 5, 13],\n",
       " [5, 6, 9, 5, 13],\n",
       " [13, 18, 18, 9, 1, 13],\n",
       " [5, 2, 5, 5, 13],\n",
       " [9, 12, 34],\n",
       " [5, 5, 2, 5, 13],\n",
       " [2, 6, 13],\n",
       " [5, 5, 5, 13, 5, 13],\n",
       " [5, 2, 12, 18, 13],\n",
       " [5, 2, 12, 23, 13, 34],\n",
       " [23, 12, 18, 5, 5, 13],\n",
       " [5, 18, 13],\n",
       " [9, 5, 23, 1, 13],\n",
       " [23, 5, 5, 13],\n",
       " [5, 2, 12, 23, 5, 13],\n",
       " [18, 1, 5, 6, 12, 13],\n",
       " [5, 12, 13, 5, 13],\n",
       " [5, 2, 23, 5, 1, 13],\n",
       " [9, 5, 29, 2, 0, 12, 13],\n",
       " [5, 2, 12, 23, 13, 34],\n",
       " [0, 5, 5, 5, 5, 13],\n",
       " [0, 5, 13],\n",
       " [9, 5, 2, 12, 23, 5, 13],\n",
       " [9, 9, 5, 9, 13],\n",
       " [5, 18, 5, 13],\n",
       " [9, 2, 12, 23, 5, 13],\n",
       " [5, 5, 2, 1, 13]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c27aa59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 18, 23, 17, 13],\n",
       " [19, 1, 20, 11, 21, 5, 13],\n",
       " [5, 18, 23, 22, 13],\n",
       " [34, 18, 23, 13, 35, 13, 34],\n",
       " [5, 2, 3, 23, 1, 13],\n",
       " [9, 18, 0, 1, 13],\n",
       " [14, 2, 15, 12, 13],\n",
       " [5, 9, 2, 29, 13],\n",
       " [5, 6, 12, 13],\n",
       " [0, 1, 6, 21, 0, 1, 13],\n",
       " [23, 1, 26, 2, 41, 13],\n",
       " [9, 2, 3, 21, 9, 13],\n",
       " [2, 12, 13],\n",
       " [5, 26, 62, 21, 0, 13],\n",
       " [5, 26, 2, 12, 13],\n",
       " [9, 6, 19, 1, 13],\n",
       " [20, 11, 0, 1, 21, 14, 1, 13],\n",
       " [20, 12, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [5, 2, 29, 5, 13],\n",
       " [5, 2, 15, 12, 13],\n",
       " [14, 2, 25, 12, 38],\n",
       " [23, 4, 1, 2, 29, 23, 17, 32, 13],\n",
       " [23, 1, 21, 5, 2, 41, 13],\n",
       " [9, 6, 23, 4, 1, 13],\n",
       " [23, 1, 18, 13],\n",
       " [2, 12, 13],\n",
       " [5, 18, 23, 48, 47, 22, 13],\n",
       " [20, 29, 13],\n",
       " [5, 2, 3, 5, 13],\n",
       " [9, 9, 18, 23, 4, 1, 13],\n",
       " [5, 18, 23, 22, 13],\n",
       " [5, 18, 23, 1, 21, 22, 13],\n",
       " [5, 2, 25, 12, 21, 4, 7, 13],\n",
       " [9, 18, 19, 24, 21, 14, 1, 13],\n",
       " [23, 7, 5, 2, 29, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 6, 21, 0, 1, 12, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [13, 6, 49, 7, 37, 13],\n",
       " [34, 18, 5, 34],\n",
       " [5, 18, 23, 1, 13],\n",
       " [0, 2, 29, 23, 1, 21, 5, 13],\n",
       " [23, 4, 1, 9, 18, 13],\n",
       " [9, 6, 0, 1, 37, 13],\n",
       " [23, 1, 2, 3, 13],\n",
       " [23, 1, 21, 53, 2, 3, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [9, 6, 39, 1, 13],\n",
       " [9, 2, 3, 23, 4, 1, 13],\n",
       " [43, 1, 6, 0, 7, 13],\n",
       " [23, 17, 2, 29, 0, 12, 1, 21, 47, 42, 22, 13],\n",
       " [23, 1, 2, 15, 16, 13],\n",
       " [9, 9, 18, 13],\n",
       " [5, 2, 3, 21, 1, 13],\n",
       " [20, 49, 12, 13],\n",
       " [9, 6, 11, 0, 1, 13],\n",
       " [5, 2, 29, 13],\n",
       " [20, 11, 0, 1, 13],\n",
       " [5, 2, 16, 13],\n",
       " [5, 2, 29, 0, 1, 12, 21, 5, 13],\n",
       " [5, 6, 23, 4, 1, 13],\n",
       " [2, 3, 21, 43, 1, 13],\n",
       " [2, 12, 13],\n",
       " [19, 1, 2, 30, 11, 13],\n",
       " [23, 1, 18, 13],\n",
       " [2, 12, 13],\n",
       " [9, 2, 29, 13],\n",
       " [5, 2, 12, 21, 0, 34],\n",
       " [45, 12, 13],\n",
       " [26, 10, 11, 14, 1, 13],\n",
       " [9, 2, 16, 13],\n",
       " [5, 2, 12, 13],\n",
       " [2, 12, 13],\n",
       " [5, 18, 13],\n",
       " [2, 3, 13],\n",
       " [9, 28, 9, 2, 39, 15, 12, 13],\n",
       " [5, 26, 2, 3, 13],\n",
       " [2, 12, 13],\n",
       " [23, 4, 1, 6, 13],\n",
       " [9, 2, 29, 23, 1, 58, 13],\n",
       " [5, 18, 13],\n",
       " [5, 2, 29, 0, 1, 21, 5, 13],\n",
       " [45, 12, 13],\n",
       " [2, 12, 13],\n",
       " [9, 2, 12, 2, 13],\n",
       " [9, 2, 29, 0, 1, 12, 13],\n",
       " [9, 26, 6, 23, 1, 13],\n",
       " [5, 26, 2, 12, 13],\n",
       " [14, 1, 2, 29, 19, 7, 13],\n",
       " [2, 3, 23, 1, 13],\n",
       " [23, 1, 2, 3, 23, 1, 13],\n",
       " [26, 9, 6, 13],\n",
       " [5, 2, 30, 11, 1, 13],\n",
       " [14, 1, 6, 19, 24, 13],\n",
       " [23, 1, 18, 21, 13],\n",
       " [5, 6, 0, 1, 37, 13],\n",
       " [2, 30, 11, 21, 0, 16, 7, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [5, 2, 12, 21, 1, 13],\n",
       " [9, 26, 2, 12, 13, 34, 34],\n",
       " [9, 26, 46, 6, 13],\n",
       " [23, 1, 2, 3, 23, 1, 13],\n",
       " [23, 1, 6, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 6, 0, 20, 7, 13],\n",
       " [5, 2, 25, 12, 21, 5, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 29, 19, 24, 20, 13],\n",
       " [5, 18, 0, 1, 12, 13],\n",
       " [5, 6, 49, 23, 1, 13],\n",
       " [23, 31, 6, 21, 23, 31, 13],\n",
       " [23, 17, 18, 23, 17, 13],\n",
       " [49, 9, 2, 12, 13],\n",
       " [34, 2, 29, 5, 34],\n",
       " [9, 2, 29, 0, 1, 12, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [5, 6, 23, 31, 13],\n",
       " [5, 6, 13],\n",
       " [21, 9, 6, 39, 1, 13],\n",
       " [23, 1, 2, 3, 13],\n",
       " [5, 6, 5, 13],\n",
       " [23, 1, 6, 13],\n",
       " [5, 6, 0, 7, 12, 13],\n",
       " [5, 6, 0, 12, 7, 13],\n",
       " [19, 1, 19, 11, 19, 13],\n",
       " [9, 18, 21, 23, 1, 13],\n",
       " [23, 1, 2, 12, 21, 31, 13],\n",
       " [5, 6, 21, 31, 13, 21, 31, 13],\n",
       " [23, 1, 6, 19, 24, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [23, 1, 2, 3, 13],\n",
       " [23, 17, 18, 23, 17, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [31, 2, 25, 12, 21, 31, 13],\n",
       " [9, 26, 2, 3, 13],\n",
       " [26, 6, 23, 1, 13],\n",
       " [26, 6, 13],\n",
       " [26, 23, 1, 2, 12, 13],\n",
       " [9, 2, 12, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 29, 13],\n",
       " [5, 18, 12, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [14, 1, 6, 52, 19, 24, 13],\n",
       " [23, 4, 7, 9, 18, 13],\n",
       " [5, 18, 0, 1, 13],\n",
       " [9, 18, 39, 13],\n",
       " [23, 7, 2, 29, 23, 4, 1, 21, 23, 1, 13],\n",
       " [5, 18, 23, 31, 13],\n",
       " [23, 17, 6, 21, 31, 13],\n",
       " [2, 12, 13],\n",
       " [2, 41],\n",
       " [34, 2, 29, 23, 35, 34],\n",
       " [34, 6, 23, 7, 23, 17, 37, 34],\n",
       " [23, 1, 18, 57, 19, 24, 13],\n",
       " [9, 18, 23, 1, 21, 0, 1, 13],\n",
       " [5, 2, 29, 13],\n",
       " [5, 2, 12, 13],\n",
       " [23, 1, 2, 3, 23, 1, 13],\n",
       " [2, 3, 13],\n",
       " [2, 29, 0, 1, 21, 9, 13],\n",
       " [5, 18, 13, 11, 23, 1, 13],\n",
       " [5, 20, 11, 21, 5, 13],\n",
       " [23, 1, 2, 3, 21, 1, 13],\n",
       " [34, 2, 29, 23, 13, 35, 13, 34],\n",
       " [34, 18, 5, 34],\n",
       " [5, 2, 11, 13],\n",
       " [9, 2, 3, 21, 1, 13],\n",
       " [6, 39, 13],\n",
       " [2, 29, 23, 1, 13],\n",
       " [39, 6, 5, 13],\n",
       " [26, 11, 43, 1, 13],\n",
       " [5, 2, 25, 12, 21, 5, 13],\n",
       " [31, 2, 25, 12, 21, 31, 13],\n",
       " [43, 26, 9, 6, 13],\n",
       " [5, 2, 3, 0, 1, 13],\n",
       " [5, 2, 12, 13],\n",
       " [23, 4, 1, 2, 41, 13],\n",
       " [9, 26, 2, 12, 13],\n",
       " [49, 9, 20, 11, 13],\n",
       " [5, 2, 15, 12, 13],\n",
       " [5, 26, 2, 15, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [0, 2, 29, 21, 5, 34],\n",
       " [5, 2, 12, 13],\n",
       " [23, 7, 18, 13],\n",
       " [9, 2, 29, 19, 24, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [5, 26, 2, 15, 12, 13],\n",
       " [5, 2, 12, 21, 1, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 2, 30, 11, 13],\n",
       " [5, 20, 12, 13],\n",
       " [23, 1, 6, 21, 23, 1, 13],\n",
       " [9, 62, 0, 1, 13],\n",
       " [9, 6, 21, 31, 13],\n",
       " [17, 2, 29, 35, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [5, 26, 2, 38, 12, 13],\n",
       " [2, 12, 13],\n",
       " [23, 7, 2, 29, 38],\n",
       " [4, 7, 18, 0, 7, 13],\n",
       " [23, 1, 6, 19, 24, 13],\n",
       " [34, 2, 29, 34],\n",
       " [9, 26, 2, 3, 23, 1, 13],\n",
       " [23, 1, 6, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [5, 9, 18, 21, 0, 1, 13],\n",
       " [5, 2, 12, 21, 19, 24, 13],\n",
       " [23, 1, 2, 29, 21, 31, 13],\n",
       " [14, 26, 6, 1, 13],\n",
       " [23, 1, 13, 35, 13, 2, 30, 11, 21, 5, 13],\n",
       " [23, 35, 18, 23, 22, 13],\n",
       " [26, 2, 29, 13],\n",
       " [39, 1, 6, 13],\n",
       " [23, 1, 18, 0, 1, 13],\n",
       " [26, 21, 9, 2, 12, 13],\n",
       " [5, 2, 49, 12, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [23, 1, 17, 6, 23, 31, 13],\n",
       " [23, 1, 13, 35, 13, 2, 30, 11, 21, 5, 13],\n",
       " [31, 2, 30, 11, 44, 1, 13],\n",
       " [39, 1, 11, 23, 1, 13],\n",
       " [23, 1, 26, 2, 12, 13],\n",
       " [34, 1, 6, 17, 34],\n",
       " [34, 1, 18, 5, 34],\n",
       " [5, 18, 13],\n",
       " [5, 6, 19, 1, 13, 21, 23, 1, 13],\n",
       " [26, 6, 43, 1, 13],\n",
       " [9, 20, 3, 0, 1, 21, 1, 13],\n",
       " [5, 9, 2, 29, 13],\n",
       " [14, 6, 0, 1, 21, 1, 13],\n",
       " [4, 7, 6, 0, 12, 7, 13],\n",
       " [26, 1, 2, 12, 13],\n",
       " [23, 1, 21, 31, 2, 12, 13],\n",
       " [0, 2, 30, 11, 34],\n",
       " [9, 2, 29, 23, 4, 1, 13],\n",
       " [23, 1, 18, 23, 1, 13],\n",
       " [49, 9, 6, 1, 13],\n",
       " [9, 2, 29, 13],\n",
       " [23, 7, 2, 29, 23, 7, 13],\n",
       " [9, 18, 0, 1, 13],\n",
       " [5, 2, 30, 11, 21, 31, 13],\n",
       " [5, 18, 0, 1, 21, 31, 13],\n",
       " [5, 18, 21, 31, 13],\n",
       " [9, 62, 23, 1, 13],\n",
       " [5, 6, 23, 1, 13],\n",
       " [23, 1, 20, 3, 0, 1, 13],\n",
       " [23, 1, 36, 2, 11, 13],\n",
       " [5, 26, 2, 12, 13],\n",
       " [5, 18, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [5, 2, 30, 11, 19, 1, 13],\n",
       " [9, 9, 18, 13],\n",
       " [2, 49, 12, 38],\n",
       " [9, 2, 29, 0, 1, 21, 5, 13],\n",
       " [23, 54, 18, 23, 22, 13],\n",
       " [23, 50, 20, 11, 23, 22, 13],\n",
       " [5, 18, 13],\n",
       " [5, 26, 2, 12, 13],\n",
       " [14, 1, 2, 15, 12, 13],\n",
       " [5, 13, 30, 11, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [9, 9, 6, 13],\n",
       " [4, 7, 18, 23, 1, 13],\n",
       " [5, 2, 12, 21, 1, 13],\n",
       " [5, 18, 19, 1, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [5, 18, 5, 13],\n",
       " [5, 18, 0, 1, 13],\n",
       " [9, 2, 29, 5, 13],\n",
       " [2, 29, 19, 1, 13],\n",
       " [21, 9, 6, 23, 1, 12, 34],\n",
       " [34, 18, 5, 34],\n",
       " [5, 18, 13],\n",
       " [9, 6, 1, 13],\n",
       " [9, 6, 21, 39, 13],\n",
       " [45, 39, 12, 13],\n",
       " [5, 2, 3, 0, 1, 12, 13],\n",
       " [23, 1, 2, 29, 23, 7, 13],\n",
       " [5, 26, 18, 1, 13],\n",
       " [5, 6, 21, 39, 13],\n",
       " [14, 1, 6, 19, 24, 13],\n",
       " [23, 4, 1, 2, 41, 13],\n",
       " [5, 6, 0, 7, 13],\n",
       " [9, 6, 11, 0, 1, 13],\n",
       " [34, 18, 5, 34],\n",
       " [14, 1, 2, 12, 13],\n",
       " [23, 7, 5, 2, 37, 13],\n",
       " [9, 6, 21, 1, 13],\n",
       " [23, 7, 6, 13],\n",
       " [23, 4, 1, 2, 37, 13],\n",
       " [23, 1, 18, 23, 53, 13],\n",
       " [9, 26, 6, 23, 1, 13],\n",
       " [5, 26, 2, 12, 13],\n",
       " [23, 1, 2, 3, 5, 2, 13],\n",
       " [5, 18, 23, 22, 13],\n",
       " [5, 2, 29, 21, 31, 13],\n",
       " [23, 1, 26, 2, 30, 11, 21, 31, 13],\n",
       " [5, 2, 29, 0, 1, 21, 23, 4, 1, 13],\n",
       " [5, 2, 3, 23, 1, 13],\n",
       " [4, 7, 6, 23, 1, 13],\n",
       " [5, 6, 0, 7, 12, 13],\n",
       " [23, 1, 20, 15, 12, 13],\n",
       " [5, 2, 3, 0, 1, 13],\n",
       " [9, 18, 0, 1, 13],\n",
       " [26, 21, 9, 9, 62, 13],\n",
       " [39, 1, 11, 13],\n",
       " [5, 6, 0, 12, 7, 13],\n",
       " [5, 9, 6, 13],\n",
       " [5, 20, 11, 21, 1, 13],\n",
       " [5, 6, 0, 7, 13],\n",
       " [34, 18, 5, 34],\n",
       " [3, 0, 1, 2, 12, 13],\n",
       " [23, 1, 20, 11, 21, 23, 1, 13],\n",
       " [5, 18, 13],\n",
       " [14, 1, 9, 6, 13],\n",
       " [3, 23, 1, 21, 58, 26, 2, 12, 13],\n",
       " [5, 9, 2, 3, 13],\n",
       " [5, 2, 3, 0, 1, 13],\n",
       " [5, 26, 6, 0, 7, 13],\n",
       " [23, 7, 18, 23, 7, 13],\n",
       " [23, 1, 26, 6, 13],\n",
       " [5, 18, 0, 1, 13],\n",
       " [5, 6, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [5, 18, 5, 13],\n",
       " [20, 3, 13],\n",
       " [23, 1, 2, 30, 15, 11, 13],\n",
       " [34, 6, 23, 7, 23, 17, 34],\n",
       " [34, 1, 6, 5, 34],\n",
       " [5, 2, 12, 21, 1, 13],\n",
       " [49, 13, 9, 2, 12, 13],\n",
       " [5, 20, 12, 13],\n",
       " [5, 2, 3, 21, 1, 21, 5, 13],\n",
       " [9, 18, 0, 37, 13],\n",
       " [9, 2, 12, 13],\n",
       " [5, 18, 0, 1, 13],\n",
       " [5, 18, 13],\n",
       " [23, 1, 18, 13],\n",
       " [5, 2, 12, 13],\n",
       " [9, 13, 2, 26, 29, 21, 1, 13],\n",
       " [9, 18, 23, 1, 21, 14, 7, 13],\n",
       " [5, 2, 3, 13],\n",
       " [4, 7, 6, 21, 1, 13],\n",
       " [19, 24, 11, 21, 19, 24, 13],\n",
       " [14, 62, 13],\n",
       " [5, 18, 5, 21, 1, 13],\n",
       " [4, 7, 2, 3, 21, 31, 13],\n",
       " [5, 2, 29, 4, 7, 13],\n",
       " [5, 18, 5, 13],\n",
       " [5, 18, 21, 17, 13],\n",
       " [5, 6, 0, 7, 13],\n",
       " [34, 18, 5, 34],\n",
       " [5, 2, 29, 19, 24, 21, 5, 13],\n",
       " [23, 17, 18, 23, 1, 32, 13],\n",
       " [26, 2, 29, 0, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [9, 20, 29, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [23, 1, 6, 13],\n",
       " [23, 1, 6, 23, 55, 1, 13],\n",
       " [2, 3, 23, 1, 41, 13],\n",
       " [5, 2, 12, 13],\n",
       " [2, 12, 13],\n",
       " [23, 1, 6, 13],\n",
       " [9, 6, 1, 13, 34, 34],\n",
       " [5, 2, 3, 13],\n",
       " [5, 18, 13],\n",
       " [9, 9, 62, 13],\n",
       " [9, 18, 23, 1, 21, 0, 1, 13],\n",
       " [23, 1, 2, 3, 13],\n",
       " [14, 1, 2, 15, 12, 13],\n",
       " [9, 26, 6, 1, 13, 34, 34],\n",
       " [5, 2, 29, 14, 1, 21, 23, 1, 13],\n",
       " [5, 18, 5, 13],\n",
       " [5, 20, 11, 23, 22, 13],\n",
       " [43, 1, 2, 29, 0, 1, 23, 1, 13],\n",
       " [9, 6, 0, 7, 13],\n",
       " [14, 1, 26, 2, 3, 2, 13],\n",
       " [5, 2, 3, 0, 1, 13],\n",
       " [5, 2, 29, 23, 4, 1, 13],\n",
       " [14, 1, 6, 13],\n",
       " [5, 18, 23, 22, 13],\n",
       " [5, 18, 21, 35, 13],\n",
       " [5, 20, 12, 13],\n",
       " [5, 18, 0, 1, 21, 31, 13],\n",
       " [43, 1, 20, 25, 12, 21, 1, 13],\n",
       " [9, 6, 0, 1, 12, 13],\n",
       " [9, 6, 3, 21, 1, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [9, 2, 29, 23, 1, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [23, 1, 6, 13],\n",
       " [5, 18, 21, 31, 13],\n",
       " [5, 2, 15, 12, 13],\n",
       " [14, 1, 6, 21, 23, 31, 13],\n",
       " [5, 6, 21, 31, 13],\n",
       " [23, 7, 18, 23, 1, 12, 13],\n",
       " [5, 2, 29, 23, 4, 1, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [5, 18, 5, 13],\n",
       " [5, 2, 29, 13],\n",
       " [9, 36, 11, 0, 1, 39, 1, 13],\n",
       " [9, 6, 0, 1, 13],\n",
       " [5, 2, 12, 13],\n",
       " [5, 18, 5, 13],\n",
       " [4, 7, 2, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [9, 2, 3, 13],\n",
       " [5, 26, 2, 29, 5, 13],\n",
       " [9, 6, 13],\n",
       " [5, 26, 6, 21, 1, 13],\n",
       " [0, 9, 2, 3, 34],\n",
       " [34, 18, 5, 34],\n",
       " [5, 2, 30, 11, 13],\n",
       " [5, 2, 3, 23, 1, 13],\n",
       " [5, 2, 29, 13],\n",
       " [5, 2, 29, 31, 44, 1, 13],\n",
       " [39, 1, 39, 18, 23, 1, 20, 12, 13],\n",
       " [5, 62, 21, 1, 13],\n",
       " [23, 1, 20, 3, 0, 1, 16, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [5, 18, 21, 5, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [17, 6, 0, 1, 37, 13],\n",
       " [23, 31, 6, 21, 1, 13],\n",
       " [34, 18, 5, 34],\n",
       " [2, 29, 0, 1, 21, 5, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [23, 1, 18, 0, 1, 13],\n",
       " [5, 2, 29, 5, 13],\n",
       " [2, 12, 34],\n",
       " [5, 26, 2, 3, 13],\n",
       " [2, 3, 13],\n",
       " [5, 9, 18, 21, 5, 13],\n",
       " [5, 2, 30, 11, 13],\n",
       " [34, 2, 29, 23, 1, 34],\n",
       " [23, 1, 6, 19, 24, 13],\n",
       " [5, 18, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [23, 1, 18, 13],\n",
       " [5, 2, 29, 23, 1, 13],\n",
       " [23, 7, 2, 49, 3, 13],\n",
       " [5, 18, 21, 5, 13],\n",
       " [5, 2, 29, 21, 17, 13],\n",
       " [9, 20, 11, 21, 0, 1, 13],\n",
       " [34, 2, 29, 23, 1, 34],\n",
       " [39, 1, 6, 44, 1, 38],\n",
       " [0, 18, 13],\n",
       " [9, 26, 2, 3, 23, 1, 13],\n",
       " [9, 6, 19, 24, 13],\n",
       " [5, 18, 5, 13],\n",
       " [9, 2, 3, 23, 1, 13],\n",
       " [5, 26, 2, 12, 13]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "583dd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=all_prediction_labels, references=all_true_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b21a7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 49},\n",
       " '1': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 147},\n",
       " '2': {'precision': 0.3443708609271523,\n",
       "  'recall': 0.3880597014925373,\n",
       "  'f1': 0.3649122807017544,\n",
       "  'number': 134},\n",
       " '3': {'precision': 0.7847593582887701,\n",
       "  'recall': 0.9347133757961783,\n",
       "  'f1': 0.8531976744186046,\n",
       "  'number': 628},\n",
       " '4': {'precision': 0.9387755102040817,\n",
       "  'recall': 0.5168539325842697,\n",
       "  'f1': 0.6666666666666667,\n",
       "  'number': 89},\n",
       " '5': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 31},\n",
       " '6': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53},\n",
       " '7': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28},\n",
       " '8': {'precision': 0.07758620689655173,\n",
       "  'recall': 0.08035714285714286,\n",
       "  'f1': 0.07894736842105264,\n",
       "  'number': 112},\n",
       " '9': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.018518518518518517,\n",
       "  'f1': 0.036036036036036036,\n",
       "  'number': 108},\n",
       " '_': {'precision': 0.345985401459854,\n",
       "  'recall': 0.34699853587115664,\n",
       "  'f1': 0.3464912280701754,\n",
       "  'number': 683},\n",
       " 'overall_precision': 0.5319270239452679,\n",
       " 'overall_recall': 0.4524733268671193,\n",
       " 'overall_f1': 0.48899371069182385,\n",
       " 'overall_accuracy': 0.5311137534680935}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0d042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

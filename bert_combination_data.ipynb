{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0a68d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianbehrendt/opt/anaconda3/envs/computational_semantics/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-02 18:28:20.242189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import datasets \n",
    "import numpy as np \n",
    "from transformers import BertTokenizerFast \n",
    "from transformers import DataCollatorForTokenClassification \n",
    "from transformers import AutoModelForTokenClassification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# https://github.com/rohan-paul/MachineLearning-DeepLearning-Code-for-my-YouTube-Channel/blob/master/NLP/YT_Fine_tuning_BERT_NER_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fd4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English training data set has 7745 sentences.\n",
      "The German training data set has 1740 sentences.\n",
      "The Dutch training data set has 538 sentences.\n",
      "The Italian training data set has 684 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('train.en.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "\n",
    "train_tags_all = []\n",
    "train_token_all =[]\n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "\n",
    "train_data_en = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token_all.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags_all.append(tags)\n",
    "            tags = []\n",
    "            train_data_en.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "\n",
    "print(\"The English training data set has\",len(train_data_en), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.de.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_de = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token_all.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags_all.append(tags)\n",
    "            tags = []\n",
    "            train_data_de.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The German training data set has\",len(train_data_de), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_nl = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token_all.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags_all.append(tags)\n",
    "            tags = []\n",
    "            train_data_nl.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The Dutch training data set has\",len(train_data_nl), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_it = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token_all.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags_all.append(tags)\n",
    "            tags = []\n",
    "            train_data_it.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The Italian training data set has\",len(train_data_it), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942eac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data has x tokens 10707 sentences.\n",
      "all data has x tokens 10707 sentences.\n"
     ]
    }
   ],
   "source": [
    "print(\"all data has x tokens\",len(train_token_all), \"sentences.\" )\n",
    "print(\"all data has x tokens\",len(train_tags_all), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79624cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 490 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8393d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64bda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = np.load('universal_dict.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649a7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_into_ints(data,mydict):\n",
    "    for sentences in range(0,len(data)):\n",
    "        sent = data[sentences]\n",
    "        for i in range(0,len(sent)):\n",
    "            word = sent[i]\n",
    "            transformation = mydict[word]\n",
    "            sent[i] = transformation\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c302d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags_transformed = train_tags_all\n",
    "test_tags_transformed = test_tags\n",
    "\n",
    "transformed_input_train = transform_into_ints(train_tags_transformed,mydict)\n",
    "transformed_input_test = transform_into_ints(test_tags_transformed,mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8db6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "         train_token_all, transformed_input_train, test_size=0.3, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47739c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tom', 'wachte', 'um', 'halb~sieben', 'auf', '.']\n",
      "['The', 'poor', 'cat', 'was', 'run', 'over', 'by', 'a', 'truck', '.']\n",
      "['Jill', 'ist', 'mit', 'Jack', 'verlobt', '.']\n",
      "['Napoleon~Bonaparte', 'was', 'born', 'in', 'Corsica', '.']\n",
      "['You', 'tortured', 'a', 'prisoner', '.']\n",
      "['Tom', 'is', 'now', 'apologizing', '.']\n",
      "['I', 'love', 'dogs', '.']\n",
      "['There', 'is', 'an', 'old', 'house', 'on', 'this', 'street', '.']\n",
      "['This', 'desk', 'was', 'too', 'heavy', 'to', 'lift', '.']\n",
      "['\"', 'He', 'is', 'an', 'American', 'political~scientist', '.', '\"']\n",
      "['My', 'name', 'is', 'Tom', 'and', 'I', \"'m\", 'an', 'addict', '.']\n",
      "['Kate', 'hat', 'das', 'Zimmer', 'nicht', 'gereinigt', '.']\n",
      "['Tom', 'is', 'very', 'young', '.']\n",
      "['I', 'refreshed', 'myself', 'with', 'a', 'hot', 'bath', '.']\n",
      "['He', \"'s\", 'always', 'breaking', 'into', 'our', 'conversation', '.']\n",
      "['She', \"'s\", 'taking', 'birth~control~pills', '.']\n",
      "['She', \"'s\", 'painting', 'her', 'room', 'white', '.']\n",
      "['Tom', 'did', \"n't\", 'like', 'his', 'sandwich', '.']\n",
      "['Né', 'Ania', 'né', 'Magdalena', 'amano', 'Justin~Bieber', '.']\n",
      "['He', 'dyed', 'his', 'hair', 'black', '.']\n"
     ]
    }
   ],
   "source": [
    "# check that sklearn shuffles the data. \n",
    "for i in range(0,20):\n",
    "    print(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce65371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({13: 7477, 1: 6050, 9: 3895, 21: 3314, 23: 2526, 18: 2520, 2: 2417, 5: 2325, 6: 1794, 12: 1647, 0: 1492, 4: 1233, 11: 1094, 34: 979, 7: 888, 20: 821, 19: 689, 26: 612, 3: 610, 31: 504, 24: 420, 29: 361, 14: 308, 39: 305, 16: 225, 45: 188, 44: 170, 15: 169, 49: 164, 38: 158, 43: 141, 25: 138, 37: 127, 17: 127, 53: 120, 41: 112, 22: 112, 8: 98, 10: 96, 42: 91, 33: 80, 51: 76, 50: 73, 35: 69, 28: 66, 52: 50, 27: 46, 30: 45, 47: 43, 40: 43, 46: 38, 62: 38, 58: 35, 36: 33, 32: 33, 48: 31, 55: 22, 61: 19, 54: 18, 63: 15, 59: 13, 57: 11, 67: 11, 60: 10, 64: 3, 65: 1, 68: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "D = y_train\n",
    "\n",
    "# Flatten the nested list\n",
    "flattened_list = [item for sublist in D for item in sublist]\n",
    "\n",
    "# Count the frequencies of each value\n",
    "counter = Counter(flattened_list)\n",
    "\n",
    "# Print the frequencies of each value\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7480bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(tokens, tags):\n",
    "    ids = []\n",
    "    token = []\n",
    "    ner_tags = []\n",
    "    for i in range(0, len(tokens)):\n",
    "        ids.append(i)\n",
    "        token.append(tokens[i])\n",
    "        ner_tags.append(tags[i])\n",
    "    return ids, token, ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b66ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get it into the correct form: https://huggingface.co/docs/datasets/v1.1.1/loading_datasets.html\n",
    "\n",
    "ids_train, tokens_train, ner_tags_train = get_ids(X_train, y_train)\n",
    "ids_val, tokens_val, ner_tags_val = get_ids(X_val, y_val)\n",
    "\n",
    "ids_test, tokens_test, ner_tags_test = get_ids(test_token, transformed_input_test)\n",
    "\n",
    "train = {'input_ids': ids_train,\n",
    "            'tokens': tokens_train,\n",
    "            'ner_tags': ner_tags_train}\n",
    "\n",
    "validation = {'input_ids': ids_val,\n",
    "            'tokens': tokens_val,\n",
    "            'ner_tags': ner_tags_val}\n",
    "\n",
    "test = {'input_ids': ids_test,\n",
    "            'tokens': tokens_test,\n",
    "            'ner_tags': ner_tags_test}\n",
    "\n",
    "train = Dataset.from_dict(train) \n",
    "validation = Dataset.from_dict(validation)\n",
    "test = Dataset.from_dict(test)\n",
    "\n",
    "data = {'train': train,\n",
    "            'validation': validation,\n",
    "            'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58347bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (/Users/julianbehrendt/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|██████████| 3/3 [00:00<00:00, 134.78it/s]\n"
     ]
    }
   ],
   "source": [
    "conll2003 = datasets.load_dataset(\"conll2003\") \n",
    "conll2003\n",
    "\n",
    "conll2003['train'] = data['train']\n",
    "conll2003['validation'] = data['validation']\n",
    "conll2003['test'] = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0c5f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 7494\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 3213\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'tokens', 'ner_tags'],\n",
       "        num_rows: 490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2605104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True): \n",
    "\n",
    "    \n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n",
    "\n",
    "    \n",
    "    labels = [] \n",
    "    for i, label in enumerate(examples[\"ner_tags\"]): \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        # word_ids() => Return a list mapping the tokens\n",
    "        # to their actual word in the initial sentence.\n",
    "        # It Returns a list indicating the word corresponding to each token. \n",
    "        \n",
    "        previous_word_idx = None \n",
    "        label_ids = []\n",
    "        # Special tokens like `<s>` and `<\\s>` are originally mapped to None \n",
    "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
    "        \n",
    "        for word_idx in word_ids: \n",
    "            if word_idx is None: \n",
    "                # set –100 as the label for these special tokens\n",
    "                label_ids.append(-100)\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # if current word_idx is != prev then its the most regular case\n",
    "                # and add the corresponding token                 \n",
    "                label_ids.append(label[word_idx]) \n",
    "            else: \n",
    "                # to take care of sub-words which have the same word_idx\n",
    "                # set -100 as well for them, but only if label_all_tokens == False\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "                # mask the subword representations after the first subword\n",
    "                 \n",
    "            previous_word_idx = word_idx \n",
    "        labels.append(label_ids) \n",
    "    tokenized_inputs[\"labels\"] = labels \n",
    "    return tokenized_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcbac28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 14.63ba/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 24.07ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.79ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae44961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels= 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0cdfb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "args = TrainingArguments( \n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\", \n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16, \n",
    "    num_train_epochs=5, \n",
    "    weight_decay=0.01, \n",
    "    eval_steps = 100,  \n",
    "    save_total_limit = 2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36830b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c63d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = datasets.load_metric(\"seqeval\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0caf3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds): \n",
    "    pred_logits, labels = eval_preds \n",
    "    \n",
    "    pred_logits = np.argmax(pred_logits, axis=2) \n",
    "    print(pred_logits)\n",
    "    # the logits and the probabilities are in the same order,\n",
    "    # so we don’t need to apply the softmax\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for i in range(len(pred_logits)):\n",
    "        pred_seq = []\n",
    "        true_seq = []\n",
    "        for j in range(len(pred_logits[i])):\n",
    "            if labels[i][j] != -100:\n",
    "                pred_seq.append(pred_logits[i][j])\n",
    "                true_seq.append(labels[i][j])\n",
    "        predictions.append(pred_seq)\n",
    "        true_labels.append(true_seq)\n",
    "    \n",
    "    results = metric.compute(predictions=predictions, references=true_labels) \n",
    "    return { \n",
    "   \"precision\": results[\"overall_precision\"], \n",
    "   \"recall\": results[\"overall_recall\"], \n",
    "   \"f1\": results[\"overall_f1\"], \n",
    "  \"accuracy\": results[\"overall_accuracy\"], \n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cfb4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( \n",
    "    model, \n",
    "    args, \n",
    "   train_dataset=tokenized_datasets[\"train\"], \n",
    "   eval_dataset=tokenized_datasets[\"validation\"], \n",
    "   data_collator=data_collator, \n",
    "   tokenizer=tokenizer, \n",
    "   compute_metrics=compute_metrics \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7140ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 7494\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2345\n",
      "  Number of trainable parameters = 108944709\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2345/2345 42:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.573670</td>\n",
       "      <td>0.841663</td>\n",
       "      <td>0.859210</td>\n",
       "      <td>0.850346</td>\n",
       "      <td>0.862779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.309900</td>\n",
       "      <td>0.368309</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.913110</td>\n",
       "      <td>0.909624</td>\n",
       "      <td>0.912908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.464500</td>\n",
       "      <td>0.307247</td>\n",
       "      <td>0.918648</td>\n",
       "      <td>0.928563</td>\n",
       "      <td>0.923579</td>\n",
       "      <td>0.925774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279400</td>\n",
       "      <td>0.283649</td>\n",
       "      <td>0.927057</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.931498</td>\n",
       "      <td>0.933881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.274555</td>\n",
       "      <td>0.930436</td>\n",
       "      <td>0.937454</td>\n",
       "      <td>0.933932</td>\n",
       "      <td>0.937117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3213\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  2 ...  0  0  0]\n",
      " [13  5  2 ...  0  0  0]\n",
      " [ 5 34  6 ...  0  0  0]\n",
      " ...\n",
      " [13  9  6 ...  0  0  0]\n",
      " [13 31  6 ...  0  0  0]\n",
      " [ 9  9  2 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-ner/checkpoint-500\n",
      "Configuration saved in test-ner/checkpoint-500/config.json\n",
      "Model weights saved in test-ner/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3213\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  2 ...  0  0  0]\n",
      " [13  5  2 ...  0  0  0]\n",
      " [ 5 34  6 ...  0  0  0]\n",
      " ...\n",
      " [13  9  6 ...  0  0  0]\n",
      " [13 31  6 ...  0  0  0]\n",
      " [13  9  2 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-ner/checkpoint-1000\n",
      "Configuration saved in test-ner/checkpoint-1000/config.json\n",
      "Model weights saved in test-ner/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3213\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  2 ...  0  0  0]\n",
      " [13  5  2 ...  0  0  0]\n",
      " [ 5 34  6 ...  0  0  0]\n",
      " ...\n",
      " [13  9  6 ...  0  0  0]\n",
      " [13 31  6 ...  0  0  0]\n",
      " [13  9  2 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-ner/checkpoint-1500\n",
      "Configuration saved in test-ner/checkpoint-1500/config.json\n",
      "Model weights saved in test-ner/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-1500/special_tokens_map.json\n",
      "Deleting older checkpoint [test-ner/checkpoint-500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3213\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  2 ...  0  0  0]\n",
      " [13  5  2 ...  0  0  0]\n",
      " [ 5 34  6 ...  0  0  0]\n",
      " ...\n",
      " [13  9  6 ...  0  0  0]\n",
      " [13 31  6 ...  0  0  0]\n",
      " [13  9  2 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test-ner/checkpoint-2000\n",
      "Configuration saved in test-ner/checkpoint-2000/config.json\n",
      "Model weights saved in test-ner/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in test-ner/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in test-ner/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [test-ner/checkpoint-1000] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3213\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  5  2 ...  0  0  0]\n",
      " [13  5  2 ...  0  0  0]\n",
      " [ 5 34  6 ...  0  0  0]\n",
      " ...\n",
      " [13  9  6 ...  0  0  0]\n",
      " [13 31  6 ...  0  0  0]\n",
      " [13  9  2 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2345, training_loss=0.5041023693613406, metrics={'train_runtime': 2578.5258, 'train_samples_per_second': 14.532, 'train_steps_per_second': 0.909, 'total_flos': 336600889275096.0, 'train_loss': 0.5041023693613406, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce72fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in bert_all_languages/config.json\n",
      "Model weights saved in bert_all_languages/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"bert_all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8f8a219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file bert_all_languages/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert_all_languages\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file bert_all_languages/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at bert_all_languages.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_fine_tuned_nl = AutoModelForTokenClassification.from_pretrained(\"bert_all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61547883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "len_test = 490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3a2454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model= model_fine_tuned_nl, tokenizer=tokenizer)\n",
    "\n",
    "all_true_labels = []\n",
    "all_prediction_labels = []\n",
    "for i in range(0,len_test):\n",
    "    test_data = conll2003['test'][i] \n",
    "    \n",
    "    true_labels = test_data['ner_tags']\n",
    "    all_true_labels.append(true_labels)\n",
    "    \n",
    "    tokens = test_data['tokens']\n",
    "    ner_predictions = nlp(tokens)\n",
    "    \n",
    "    prediction_labels = []\n",
    "    for i in range(0, len(ner_predictions)):\n",
    "        x = ner_predictions[i]\n",
    "        s = x[0]\n",
    "        string = s['entity']\n",
    "        label = int(re.search(r'\\d+', string).group())\n",
    "        prediction_labels.append(label)\n",
    "    \n",
    "    \n",
    "    all_prediction_labels.append(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "199cb1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 2, 1, 6, 13],\n",
       " [5, 18, 21, 1, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [5, 5, 9, 18, 21, 31, 13],\n",
       " [21, 18, 1, 3, 21, 18, 13],\n",
       " [5, 6, 19, 24, 7, 5, 9, 13],\n",
       " [9, 12, 9, 13],\n",
       " [5, 45, 39, 1, 7, 13],\n",
       " [1, 41, 9, 39, 6, 5, 13],\n",
       " [9, 6, 6, 17, 12, 3, 13],\n",
       " [18, 7, 6, 1, 5, 1, 34],\n",
       " [9, 17, 13, 1, 13],\n",
       " [5, 6, 38, 13],\n",
       " [9, 6, 21, 9, 1, 13],\n",
       " [11, 2, 5, 5, 6, 13],\n",
       " [21, 5, 39, 7, 9, 13, 13, 5, 13],\n",
       " [5, 6, 1, 13],\n",
       " [9, 6, 21, 1, 38],\n",
       " [5, 18, 21, 22, 13],\n",
       " [31, 7, 21, 17, 13],\n",
       " [5, 6, 21, 22, 13, 11, 1, 13],\n",
       " [5, 6, 5, 5, 9, 7, 13],\n",
       " [9, 11, 4, 1, 26, 18, 13],\n",
       " [13, 5, 21, 4, 39, 6, 49, 13],\n",
       " [9, 5, 26, 21, 9, 13],\n",
       " [9, 2, 19, 24, 6, 21, 14, 5, 13],\n",
       " [9, 11, 21, 12, 9, 1, 13],\n",
       " [7, 5, 5, 13],\n",
       " [9, 6, 39, 21, 4, 39, 13],\n",
       " [9, 19, 0, 5, 13],\n",
       " [9, 6, 1, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 9, 21, 0, 11, 18, 13],\n",
       " [9, 5, 18, 21, 17, 13],\n",
       " [5, 18, 21, 1, 13],\n",
       " [5, 2, 9, 18, 13],\n",
       " [9, 9, 38, 5, 7, 13],\n",
       " [9, 18, 38, 12, 13],\n",
       " [9, 5, 5, 43, 9, 11, 11, 13],\n",
       " [9, 5, 26, 18, 24, 39, 13],\n",
       " [13, 17, 6, 1, 5, 13],\n",
       " [9, 6, 21, 21, 1, 13],\n",
       " [13, 6, 53, 13],\n",
       " [9, 11, 21, 5, 54, 18, 13],\n",
       " [5, 6, 26, 18, 7, 13],\n",
       " [14, 6, 2, 0, 1, 5, 13],\n",
       " [5, 6, 0, 7, 21, 9, 13],\n",
       " [26, 9, 14, 1, 6, 13],\n",
       " [9, 6, 39, 13],\n",
       " [4, 7, 18, 21, 17, 49, 13],\n",
       " [2, 13],\n",
       " [1, 13, 9, 13, 5, 13],\n",
       " [9, 6, 21, 9, 13],\n",
       " [9, 18, 13, 31, 21, 21, 17, 13],\n",
       " [14, 6, 4, 1, 13],\n",
       " [9, 5, 11, 13],\n",
       " [5, 6, 1, 21, 5, 13],\n",
       " [4, 39, 6, 5, 13],\n",
       " [9, 9, 4, 7, 1, 26, 1, 13],\n",
       " [12, 11, 9, 21, 5, 13],\n",
       " [18, 49, 20, 9, 32, 11, 34],\n",
       " [9, 5, 7, 21, 13, 1, 13],\n",
       " [9, 6, 21, 11, 3, 13],\n",
       " [21, 18, 17, 6, 26, 13],\n",
       " [9, 5, 21, 0, 1, 13, 34, 4, 7, 6, 21, 13, 50, 13],\n",
       " [26, 2, 13, 1, 18, 13],\n",
       " [9, 18, 13, 1, 18, 0, 1, 13],\n",
       " [9, 5, 6, 39, 26, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 6, 6, 1, 13],\n",
       " [9, 20, 9, 13],\n",
       " [6, 39, 1, 6, 17, 13],\n",
       " [9, 9, 0, 1, 13],\n",
       " [4, 7, 6, 38, 19, 13],\n",
       " [21, 6, 38, 13, 21, 6, 6, 13, 13, 18, 1, 13, 21, 19, 39, 13, 21, 5, 6, 13],\n",
       " [6, 17, 45, 21, 19, 47, 22, 18, 0, 1, 21, 21, 1, 11, 34],\n",
       " [18, 49, 6, 5, 11, 34],\n",
       " [39, 1, 13],\n",
       " [11, 17, 18, 21, 13, 21, 6, 13],\n",
       " [9, 17, 6, 1, 13],\n",
       " [5, 39, 1, 13, 5, 5, 13],\n",
       " [21, 38, 13, 9, 12, 6, 1, 18, 13, 5, 13],\n",
       " [5, 11, 21, 9, 1, 13, 5, 6, 13],\n",
       " [9, 6, 26, 38, 13],\n",
       " [13, 1, 6, 18, 13],\n",
       " [9, 6, 4, 17, 11, 13],\n",
       " [9, 9, 5, 26, 11, 13],\n",
       " [5, 6, 21, 17, 1, 13],\n",
       " [39, 5, 9, 13],\n",
       " [49, 9, 1, 21, 14, 1, 34],\n",
       " [9, 6, 6, 21, 9, 7, 13],\n",
       " [9, 20, 9, 6, 49, 21, 13],\n",
       " [9, 6, 11, 18, 21, 6, 13],\n",
       " [4, 7, 13, 1, 31, 13],\n",
       " [9, 5, 18, 21, 5, 13],\n",
       " [9, 45, 1, 0, 6, 7, 12, 13],\n",
       " [9, 6, 21, 1, 11, 21, 9, 13],\n",
       " [9, 6, 21, 5, 11, 13],\n",
       " [13, 20, 20, 13],\n",
       " [9, 5, 0, 1, 13, 6, 13, 11, 13],\n",
       " [9, 2, 0, 5, 11, 13],\n",
       " [5, 6, 0, 1, 21, 18, 13],\n",
       " [9, 6, 26, 6, 13],\n",
       " [9, 6, 19, 13],\n",
       " [13, 1, 1, 6, 32, 19, 13],\n",
       " [39, 6, 18, 13],\n",
       " [31, 6, 21, 31, 13],\n",
       " [31, 18, 21, 34, 13],\n",
       " [9, 6, 26, 9, 12, 21, 9, 7, 13],\n",
       " [9, 6, 5, 7, 5, 9, 13],\n",
       " [9, 9, 11, 11, 13],\n",
       " [9, 18, 0, 7, 13],\n",
       " [13, 11, 6, 39, 39, 38],\n",
       " [17, 18, 1, 13],\n",
       " [5, 6, 21, 5, 18, 13],\n",
       " [9, 1, 21, 1, 21, 13],\n",
       " [9, 6, 43, 17, 11, 13],\n",
       " [31, 6, 5, 21, 31],\n",
       " [5, 2, 26, 17, 13],\n",
       " [26, 6, 21, 17, 13],\n",
       " [5, 45, 1, 21, 5, 11, 13],\n",
       " [9, 20, 38, 12, 21, 9, 13],\n",
       " [5, 45, 18, 6, 7, 21, 17, 13],\n",
       " [5, 9, 26, 5, 34],\n",
       " [38, 6, 13, 1, 34],\n",
       " [9, 5, 39, 26, 5, 13],\n",
       " [6, 14, 17, 5, 34],\n",
       " [1, 5, 2, 5, 1, 0, 11, 13],\n",
       " [4, 7, 6, 18, 13],\n",
       " [9, 5, 11, 13],\n",
       " [21, 1, 20, 1, 1, 13],\n",
       " [9, 6, 19, 26, 13],\n",
       " [9, 7, 6, 31, 13],\n",
       " [9, 45, 31, 11, 13],\n",
       " [9, 5, 5, 5, 9, 13],\n",
       " [5, 20, 1, 6, 21, 5, 13],\n",
       " [5, 13, 5, 11, 3, 13],\n",
       " [21, 1, 6, 9, 13],\n",
       " [5, 9, 21, 0, 5, 13],\n",
       " [13, 1, 6, 11, 13],\n",
       " [5, 20, 1, 1, 13],\n",
       " [13, 6, 35, 13],\n",
       " [13, 20, 26, 6, 13],\n",
       " [9, 18, 0, 5, 13],\n",
       " [7, 18, 21, 31, 13],\n",
       " [5, 5, 1, 21, 17, 9, 13, 1, 13],\n",
       " [5, 11, 1, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 6, 7, 1, 13],\n",
       " [9, 18, 9, 6, 7, 13],\n",
       " [4, 7, 6, 9, 0, 1, 13],\n",
       " [9, 6, 13, 21, 7, 1, 24, 13],\n",
       " [9, 18, 9, 7, 5, 13],\n",
       " [9, 9, 34, 13],\n",
       " [13, 18, 9, 21, 1, 13],\n",
       " [49, 2, 21, 39, 18, 34],\n",
       " [16, 9, 1, 13],\n",
       " [21, 17, 1, 21, 7, 13],\n",
       " [49, 6, 21, 39, 21, 21, 31, 17, 34],\n",
       " [2, 9, 0, 7, 34],\n",
       " [9, 6, 6, 21, 18, 11, 13],\n",
       " [5, 2, 0, 1, 3, 21, 5, 13],\n",
       " [0, 5, 6, 32, 19, 21, 21, 38, 13],\n",
       " [5, 45, 11, 1, 5, 13],\n",
       " [5, 6, 0, 1, 9, 6, 13],\n",
       " [9, 6, 13, 21, 1, 21, 32, 18, 13],\n",
       " [21, 1, 6, 1, 13, 11, 13],\n",
       " [49, 18, 21, 54, 34],\n",
       " [9, 5, 11, 18, 5, 13],\n",
       " [4, 7, 6, 21, 31, 11, 13],\n",
       " [4, 1, 6, 1, 18, 0, 1, 13],\n",
       " [17, 45, 18, 21, 31, 13],\n",
       " [13, 6, 13, 13],\n",
       " [9, 1, 6, 13],\n",
       " [21, 5, 6, 21, 13],\n",
       " [21, 1, 21, 21, 5, 20, 6, 21, 0, 11, 18, 13],\n",
       " [9, 1, 21, 5, 13],\n",
       " [9, 5, 1, 21, 5, 13],\n",
       " [9, 9, 1, 34],\n",
       " [4, 1, 6, 31, 13],\n",
       " [21, 5, 19, 6, 21, 1, 13],\n",
       " [3, 11, 31, 13],\n",
       " [5, 2, 21, 1, 11, 13],\n",
       " [12, 18, 21, 22, 13],\n",
       " [9, 7, 0, 1, 21, 13, 1, 13],\n",
       " [14, 1, 6, 12, 9, 1, 1, 13],\n",
       " [11, 18, 2, 11, 7, 18, 32, 11, 13],\n",
       " [5, 6, 9, 1, 13],\n",
       " [43, 6, 26, 3, 13],\n",
       " [6, 9, 1, 3, 34],\n",
       " [5, 11, 21, 17, 13],\n",
       " [13, 1, 20, 26, 1, 13],\n",
       " [4, 6, 5, 6, 13],\n",
       " [9, 6, 4, 1, 18, 13],\n",
       " [9, 2, 6, 1, 11, 13],\n",
       " [17, 18, 17, 13],\n",
       " [21, 17, 6, 6, 21, 22, 13],\n",
       " [9, 6, 9, 1, 3, 13],\n",
       " [7, 39, 21, 6, 21, 21, 7, 13],\n",
       " [9, 6, 13, 9, 5, 12, 13],\n",
       " [9, 9, 6, 9, 7, 6, 13],\n",
       " [39, 1, 9, 49, 13],\n",
       " [5, 2, 0, 1, 13],\n",
       " [6, 43, 26, 6, 34],\n",
       " [9, 9, 5, 11, 13],\n",
       " [4, 49, 6, 6, 13],\n",
       " [21, 18, 6, 39, 38],\n",
       " [5, 6, 19, 39, 17, 13],\n",
       " [21, 1, 13, 1, 13, 45, 18, 1, 5, 13],\n",
       " [21, 17, 18, 21, 22, 13],\n",
       " [9, 6, 12, 21, 6, 13],\n",
       " [1, 6, 1, 11, 31, 13, 19, 31, 13],\n",
       " [5, 11, 21, 21, 9, 26, 17, 13],\n",
       " [4, 1, 6, 51, 9, 38, 4, 5, 9, 13],\n",
       " [9, 9, 39, 9, 13, 5, 13],\n",
       " [9, 5, 12, 21, 1, 13],\n",
       " [21, 17, 17, 6, 1, 31, 13],\n",
       " [21, 1, 13, 1, 13, 45, 18, 1, 5, 13],\n",
       " [31, 45, 18, 5, 11, 13],\n",
       " [0, 1, 6, 1, 21, 13],\n",
       " [9, 20, 6, 21, 21, 18, 13],\n",
       " [9, 18, 21, 21, 6, 19, 13],\n",
       " [9, 2, 0, 7, 18, 21, 39, 5, 13],\n",
       " [13, 1, 6, 26, 1, 13],\n",
       " [9, 6, 5, 5, 6, 39, 13],\n",
       " [9, 17, 4, 5, 13],\n",
       " [9, 5, 9, 34, 13],\n",
       " [6, 1, 6, 19, 24, 39, 13],\n",
       " [9, 6, 11, 13],\n",
       " [9, 9, 12, 13],\n",
       " [9, 2, 5, 19, 17, 13],\n",
       " [26, 6, 12, 13],\n",
       " [39, 18, 9, 1, 13],\n",
       " [21, 6, 2, 19, 1, 18, 13],\n",
       " [9, 11, 6, 13, 5, 13, 6, 13],\n",
       " [26, 6, 21, 17, 13],\n",
       " [9, 5, 13, 26, 11, 13],\n",
       " [5, 45, 18, 21, 31, 13],\n",
       " [5, 6, 0, 39, 21, 31, 13],\n",
       " [21, 31, 17, 5, 1, 21, 21, 17, 13],\n",
       " [13, 18, 21, 3, 6, 1, 13],\n",
       " [9, 20, 1, 26, 11, 13],\n",
       " [9, 9, 19, 1, 21, 31, 13],\n",
       " [9, 11, 21, 1, 6, 13],\n",
       " [9, 39, 0, 1, 21, 21, 1, 13],\n",
       " [13, 6, 39, 1, 11, 13],\n",
       " [5, 9, 1, 13],\n",
       " [5, 1, 13],\n",
       " [9, 9, 31, 21, 21, 13, 13],\n",
       " [17, 1, 34],\n",
       " [38, 6, 5, 11, 21, 34],\n",
       " [49, 2, 1, 18, 34],\n",
       " [9, 11, 5, 13, 6, 9, 12, 6, 13],\n",
       " [13, 5, 6, 5, 13],\n",
       " [5, 5, 13, 21, 11, 1, 13],\n",
       " [5, 11, 26, 6, 13],\n",
       " [1, 18, 1, 6, 21, 5, 5, 34],\n",
       " [9, 6, 21, 18, 21, 19, 24, 13],\n",
       " [5, 9, 1, 1, 1, 13],\n",
       " [9, 6, 0, 1, 13, 5, 18, 13],\n",
       " [9, 6, 19, 1, 18, 13],\n",
       " [6, 9, 21, 2, 6, 34],\n",
       " [9, 18, 0, 26, 21, 21, 1],\n",
       " [9, 20, 38, 11, 31, 9, 14, 5, 1, 18, 13],\n",
       " [9, 6, 17, 13],\n",
       " [13, 1, 21, 1, 6, 1, 13],\n",
       " [9, 6, 21, 18, 21, 19, 24, 18, 13],\n",
       " [9, 18, 0, 51, 13],\n",
       " [5, 6, 9, 1, 21, 13],\n",
       " [9, 5, 19, 24, 13],\n",
       " [5, 20, 11, 18, 5, 13],\n",
       " [5, 5, 21, 1, 6, 13],\n",
       " [9, 11, 9, 6, 9, 12, 6, 13],\n",
       " [21, 9, 6, 19, 24, 13],\n",
       " [5, 11, 21, 21, 1, 9, 11, 13],\n",
       " [21, 17, 18, 18, 1, 6, 13],\n",
       " [4, 39, 6, 21, 0, 18, 13],\n",
       " [9, 6, 5, 13, 11, 13],\n",
       " [9, 13, 13, 1, 18, 5, 13],\n",
       " [4, 7, 6, 0, 1, 1, 13],\n",
       " [9, 6, 18, 13],\n",
       " [4, 7, 6, 19, 24, 7, 5, 9, 13, 34, 9, 6, 6, 24, 25, 13],\n",
       " [49, 6, 21, 5, 7, 34],\n",
       " [9, 6, 0, 6, 1, 13],\n",
       " [9, 6, 0, 12, 18, 13],\n",
       " [21, 17, 18, 21, 22, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [13, 6, 13],\n",
       " [9, 6, 5, 5, 5, 9, 13],\n",
       " [9, 18, 21, 21, 43, 39, 13],\n",
       " [6, 1, 6, 5, 13, 5, 13, 6, 18, 34],\n",
       " [9, 13, 21, 17, 31, 38],\n",
       " [5, 18, 13, 1, 13],\n",
       " [21, 13, 20, 38, 12, 13],\n",
       " [11, 6, 9, 11, 13],\n",
       " [0, 9, 11, 13],\n",
       " [5, 45, 11, 21, 18, 13],\n",
       " [9, 11, 21, 6, 13],\n",
       " [18, 9, 11, 34],\n",
       " [5, 6, 0, 17, 13],\n",
       " [9, 9, 3, 21, 9, 1, 13],\n",
       " [5, 6, 21, 1, 11, 13],\n",
       " [9, 9, 26, 13],\n",
       " [9, 6, 0, 3, 17, 13],\n",
       " [5, 9, 0, 6, 13],\n",
       " [5, 11, 0, 11, 13],\n",
       " [9, 20, 32, 11, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [13, 1, 6, 13, 5, 13, 13],\n",
       " [21, 3, 1, 19, 24, 13],\n",
       " [13, 18, 7, 19, 24, 13],\n",
       " [9, 11, 21, 21, 5, 21, 0, 5, 13],\n",
       " [39, 0, 13, 9, 18, 11, 9, 13],\n",
       " [9, 1, 0, 1, 21, 0, 1, 13],\n",
       " [5, 2, 26, 17, 13],\n",
       " [13, 5, 6, 1, 13],\n",
       " [21, 6, 18, 2, 6, 13, 17, 34],\n",
       " [9, 18, 5, 5, 9, 13],\n",
       " [9, 5, 18, 21, 5, 9, 6, 13],\n",
       " [9, 5, 18, 5, 21, 17, 6, 13],\n",
       " [5, 2, 9, 18, 13],\n",
       " [9, 11, 13, 5, 13],\n",
       " [9, 6, 11, 21, 21, 5, 13],\n",
       " [49, 6, 17, 21, 17, 34],\n",
       " [6, 1, 2, 5, 34],\n",
       " [5, 6, 12, 21, 5, 13],\n",
       " [5, 6, 1, 13],\n",
       " [21, 17, 6, 1, 21, 21, 37, 13],\n",
       " [21, 1, 21, 21, 31, 20, 6, 18, 1, 13],\n",
       " [9, 6, 21, 5, 21, 14, 7, 18, 13],\n",
       " [9, 6, 1, 21, 21, 1, 13],\n",
       " [4, 7, 11, 26, 31, 13],\n",
       " [5, 18, 19, 24, 18, 13],\n",
       " [6, 1, 6, 9, 34],\n",
       " [9, 6, 21, 18, 13],\n",
       " [0, 24, 6, 12, 21, 7, 24, 13],\n",
       " [5, 1, 5, 21, 21, 5, 13],\n",
       " [9, 5, 12, 21, 1, 13],\n",
       " [13, 20, 53, 13],\n",
       " [5, 18, 21, 9, 13],\n",
       " [5, 6, 0, 7, 13],\n",
       " [9, 17, 9, 19, 24, 13],\n",
       " [9, 18, 5, 21, 21, 17, 13],\n",
       " [38, 6, 5, 18, 34],\n",
       " [21, 1, 5, 21, 21, 31, 13],\n",
       " [9, 39, 38, 53, 17, 13],\n",
       " [21, 38, 6, 6, 13],\n",
       " [13, 6, 53, 13],\n",
       " [5, 6, 21, 13, 5, 21, 21, 1, 13],\n",
       " [5, 6, 17, 13],\n",
       " [17, 6, 26, 12, 21, 31, 13],\n",
       " [9, 18, 21, 5, 31, 9, 31, 11, 13],\n",
       " [4, 6, 9, 21, 0, 3, 13],\n",
       " [9, 6, 5, 1, 13],\n",
       " [9, 45, 7, 21, 21, 1, 1, 19, 7, 6, 13],\n",
       " [1, 31, 6, 26, 18, 21, 1, 13],\n",
       " [9, 6, 26, 7, 5, 9, 13],\n",
       " [17, 18, 21, 22, 0, 5, 24, 13],\n",
       " [11, 9, 17, 5, 6, 34],\n",
       " [9, 6, 9, 13],\n",
       " [9, 11, 21, 12, 13],\n",
       " [11, 20, 9, 5, 13],\n",
       " [9, 20, 11, 13, 17, 13],\n",
       " [21, 5, 7, 13],\n",
       " [4, 7, 9, 38, 1, 13],\n",
       " [21, 7, 45, 1, 7, 39, 13],\n",
       " [9, 11, 9, 38],\n",
       " [5, 18, 5, 13],\n",
       " [21, 1, 7, 21, 21, 49, 21, 21, 5, 13],\n",
       " [43, 12, 5, 0, 18, 13, 21, 7, 13],\n",
       " [14, 6, 0, 5, 24, 39, 13],\n",
       " [21, 17, 6, 1, 21, 21, 37, 13],\n",
       " [9, 6, 13, 5, 35, 1, 13],\n",
       " [5, 5, 9, 1, 13],\n",
       " [13, 6, 1, 13],\n",
       " [5, 39, 21, 35, 13],\n",
       " [9, 18, 13, 6, 21, 9, 6, 21, 13],\n",
       " [21, 6, 6, 0, 5, 14, 13],\n",
       " [38, 18, 5, 34],\n",
       " [9, 2, 7, 13],\n",
       " [5, 18, 21, 7, 13, 5, 13],\n",
       " [4, 7, 6, 21, 0, 1, 13],\n",
       " [5, 6, 26, 1, 32, 11, 13],\n",
       " [5, 5, 45, 18, 21, 31, 13],\n",
       " [9, 18, 9, 38, 53, 13],\n",
       " [9, 5, 0, 5, 13],\n",
       " [21, 5, 45, 9, 38, 53, 13],\n",
       " [6, 1, 11, 9, 21, 21, 34, 34],\n",
       " [3, 5, 18, 21, 22, 13],\n",
       " [49, 6, 13, 17, 34],\n",
       " [5, 2, 5, 19, 1, 18, 13],\n",
       " [4, 49, 6, 18, 13, 34, 4, 1, 6, 9, 13],\n",
       " [9, 6, 51, 21, 9, 13],\n",
       " [9, 5, 12, 18, 4, 7, 13],\n",
       " [9, 6, 0, 26, 1, 21, 50, 13],\n",
       " [49, 11, 13, 31, 13, 34],\n",
       " [9, 6, 1, 18, 5, 34],\n",
       " [13, 18, 1, 21, 13, 50, 21, 17, 13],\n",
       " [5, 45, 18, 21, 17, 13],\n",
       " [5, 18, 9, 7, 5, 13],\n",
       " [9, 5, 1, 21, 9, 1, 13, 18, 13, 13],\n",
       " [43, 6, 0, 51, 12, 13],\n",
       " [21, 19, 5, 18, 21, 13, 20, 13],\n",
       " [9, 6, 19, 24, 7, 5, 9, 13],\n",
       " [21, 7, 18, 13, 6, 13],\n",
       " [21, 1, 2, 13, 18, 20, 6, 13],\n",
       " [21, 9, 20, 1, 13],\n",
       " [43, 6, 0, 38, 11, 13],\n",
       " [21, 1, 6, 1, 1, 13],\n",
       " [5, 1, 5, 21, 17, 13],\n",
       " [49, 6, 14, 49, 1, 34],\n",
       " [17, 6, 11, 1, 17, 13],\n",
       " [1, 5, 2, 19, 1, 13],\n",
       " [4, 7, 6, 38, 13],\n",
       " [9, 6, 5, 5, 9, 7, 13],\n",
       " [9, 6, 5, 5, 5, 9, 13],\n",
       " [5, 18, 9, 5, 13],\n",
       " [21, 18, 21, 21, 19, 6, 1, 13],\n",
       " [9, 6, 7, 21, 9, 13],\n",
       " [9, 6, 19, 7, 13],\n",
       " [9, 6, 13, 13],\n",
       " [9, 6, 5, 13],\n",
       " [9, 19, 0, 34, 21, 13, 1, 13],\n",
       " [5, 5, 0, 6, 11, 13],\n",
       " [5, 18, 21, 47, 13],\n",
       " [6, 7, 2, 5, 34],\n",
       " [6, 18, 5, 34],\n",
       " [13, 17, 21, 21, 5, 21, 13, 17, 13],\n",
       " [4, 5, 45, 1, 13],\n",
       " [17, 18, 17, 13],\n",
       " [9, 13, 9, 12, 13],\n",
       " [21, 1, 6, 38, 53, 13],\n",
       " [9, 5, 5, 13],\n",
       " [0, 7, 17, 1, 5, 13],\n",
       " [5, 11, 26, 38, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 5, 12, 13],\n",
       " [5, 6, 18, 13],\n",
       " [9, 21, 13, 13],\n",
       " [9, 6, 12, 13],\n",
       " [9, 5, 5, 5, 9, 13],\n",
       " [5, 20, 0, 7, 13],\n",
       " [9, 18, 5, 5, 9, 13],\n",
       " [9, 5, 0, 1, 13],\n",
       " [5, 18, 21, 5, 13],\n",
       " [5, 45, 18, 21, 31, 13],\n",
       " [17, 6, 0, 18, 17, 13],\n",
       " [4, 5, 20, 1, 13],\n",
       " [49, 2, 21, 38, 1, 34],\n",
       " [21, 1, 13, 9, 18, 2, 9, 12, 13],\n",
       " [1, 5, 6, 21, 0, 1, 13],\n",
       " [14, 18, 7, 11, 24, 13],\n",
       " [14, 18, 6, 0, 39, 5, 13],\n",
       " [9, 45, 19, 24, 6, 13],\n",
       " [43, 6, 4, 7, 13],\n",
       " [13, 6, 9, 39, 34],\n",
       " [9, 26, 5, 13, 5, 13, 13],\n",
       " [9, 5, 0, 1, 21, 21, 1, 13],\n",
       " [9, 6, 21, 1, 26, 17, 11, 13],\n",
       " [9, 6, 6, 21, 6, 38, 13],\n",
       " [9, 13, 18, 9, 13, 31, 13],\n",
       " [13, 6, 21, 1, 21, 19, 34],\n",
       " [9, 2, 7, 22, 5, 13],\n",
       " [5, 9, 21, 31, 34],\n",
       " [49, 6, 21, 7, 21, 21, 1, 34],\n",
       " [9, 1, 13, 21, 1, 13],\n",
       " [39, 0, 11, 5, 1, 13],\n",
       " [13, 6, 53, 13],\n",
       " [21, 1, 21, 5, 20, 6, 21, 9, 13],\n",
       " [5, 1, 0, 24, 21, 31, 18, 9, 7, 13],\n",
       " [21, 1, 6, 1, 24, 39, 13],\n",
       " [3, 5, 6, 13, 17, 13],\n",
       " [7, 1, 5, 21, 13],\n",
       " [5, 18, 21, 17, 13],\n",
       " [9, 6, 18, 21, 17, 19, 11, 13],\n",
       " [9, 11, 21, 1, 6, 1, 13],\n",
       " [9, 5, 21, 21, 18, 1, 13],\n",
       " [19, 1, 19, 6, 39, 13],\n",
       " [9, 45, 1, 1, 0, 6, 13],\n",
       " [9, 5, 32, 6, 13],\n",
       " [9, 39, 39, 9, 1, 13],\n",
       " [49, 2, 1, 6, 34],\n",
       " [9, 6, 11, 18, 0, 17, 13],\n",
       " [43, 1, 6, 26, 5, 5, 0, 17, 13],\n",
       " [17, 6, 12, 21, 31, 13],\n",
       " [21, 17, 18, 19, 24, 13],\n",
       " [14, 17, 18, 9, 18, 13],\n",
       " [9, 5, 21, 21, 1, 13],\n",
       " [5, 35, 21, 1, 13],\n",
       " [13, 20, 21, 39, 21, 21, 7, 21, 5, 34]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c27aa59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[17, 2, 17, 29, 13],\n",
       " [5, 18, 19, 1, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [7, 5, 55, 18, 21, 31, 13],\n",
       " [4, 1, 18, 21, 23, 1, 13],\n",
       " [5, 2, 19, 24, 25, 21, 9, 13],\n",
       " [9, 18, 9, 13],\n",
       " [5, 20, 11, 21, 7, 13],\n",
       " [7, 5, 4, 1, 2, 16, 13],\n",
       " [9, 2, 12, 4, 1, 29, 13],\n",
       " [34, 1, 2, 21, 5, 11, 34],\n",
       " [9, 6, 21, 1, 13],\n",
       " [5, 6, 12, 13],\n",
       " [9, 2, 23, 1, 29, 13],\n",
       " [10, 2, 5, 5, 29, 13],\n",
       " [23, 16, 1, 1, 6, 21, 43, 1, 13],\n",
       " [5, 6, 1, 13],\n",
       " [9, 6, 21, 1, 38],\n",
       " [5, 18, 21, 22, 13],\n",
       " [31, 6, 21, 31, 13],\n",
       " [5, 18, 21, 22, 23, 1, 21, 13],\n",
       " [5, 2, 25, 21, 4, 7, 13],\n",
       " [9, 10, 4, 1, 26, 11, 13],\n",
       " [23, 1, 21, 4, 1, 2, 41, 13],\n",
       " [9, 6, 26, 21, 9, 13],\n",
       " [9, 2, 19, 24, 29, 21, 14, 1, 13],\n",
       " [9, 18, 23, 1, 13, 11, 13],\n",
       " [7, 5, 18, 13],\n",
       " [9, 2, 11, 21, 4, 1, 13],\n",
       " [9, 6, 0, 1, 13],\n",
       " [9, 6, 1, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 6, 21, 0, 12, 1, 13],\n",
       " [9, 2, 29, 21, 31, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [5, 2, 9, 29, 13],\n",
       " [13, 6, 49, 37, 7, 13],\n",
       " [9, 2, 15, 12, 13],\n",
       " [9, 2, 12, 8, 9, 45, 11, 13],\n",
       " [9, 2, 26, 19, 24, 16, 13],\n",
       " [23, 1, 2, 15, 16, 13],\n",
       " [9, 6, 21, 23, 1, 13],\n",
       " [9, 2, 53, 13],\n",
       " [9, 45, 23, 1, 49, 11, 13],\n",
       " [5, 6, 26, 12, 7, 13],\n",
       " [14, 1, 6, 0, 12, 1, 13],\n",
       " [5, 6, 0, 7, 21, 9, 13],\n",
       " [26, 10, 14, 1, 11, 13],\n",
       " [9, 2, 16, 13],\n",
       " [4, 7, 18, 23, 1, 41, 13],\n",
       " [56, 38],\n",
       " [45, 62, 9, 21, 31, 13],\n",
       " [9, 6, 21, 9, 13],\n",
       " [9, 18, 21, 31, 21, 23, 1, 13],\n",
       " [14, 6, 4, 1, 13],\n",
       " [9, 2, 12, 13],\n",
       " [5, 6, 0, 21, 5, 13],\n",
       " [4, 1, 6, 51, 13],\n",
       " [9, 10, 4, 12, 1, 26, 11, 13],\n",
       " [2, 6, 9, 21, 31, 13],\n",
       " [21, 34, 20, 9, 63, 11, 34],\n",
       " [4, 1, 6, 21, 23, 1, 13],\n",
       " [9, 2, 23, 1, 29, 13],\n",
       " [23, 41, 1, 2, 12, 13],\n",
       " [9, 6, 21, 0, 1, 13, 27, 4, 7, 6, 21, 23, 1, 13],\n",
       " [26, 2, 23, 1, 29, 13],\n",
       " [9, 18, 23, 1, 21, 0, 1, 13],\n",
       " [9, 6, 9, 38, 26, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 18, 4, 7, 13],\n",
       " [9, 6, 46, 13],\n",
       " [4, 40, 1, 6, 17, 13],\n",
       " [9, 6, 0, 1, 13],\n",
       " [4, 7, 2, 15, 12, 13],\n",
       " [23, 1, 6, 39, 23, 1, 6, 39, 23, 1, 6, 39, 23, 1, 6, 39, 23, 1, 6, 13],\n",
       " [34, 7, 20, 21, 48, 47, 22, 21, 0, 1, 21, 23, 1, 11, 34],\n",
       " [21, 34, 2, 5, 12, 34],\n",
       " [39, 18, 13],\n",
       " [4, 1, 18, 21, 21, 23, 1, 13],\n",
       " [4, 1, 6, 21, 13],\n",
       " [5, 18, 1, 39, 5, 18, 13],\n",
       " [23, 1, 39, 0, 6, 6, 21, 1, 28, 1, 13],\n",
       " [5, 18, 21, 4, 1, 33, 18, 21, 13],\n",
       " [9, 2, 15, 12, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [9, 2, 4, 1, 29, 13],\n",
       " [9, 10, 9, 26, 11, 13],\n",
       " [5, 6, 23, 37, 1, 13],\n",
       " [0, 6, 9, 13],\n",
       " [10, 9, 11, 21, 14, 1, 34],\n",
       " [9, 2, 12, 21, 4, 7, 13],\n",
       " [9, 18, 4, 1, 12, 21, 13],\n",
       " [9, 2, 12, 21, 23, 1, 13],\n",
       " [4, 7, 6, 21, 31, 13],\n",
       " [9, 2, 12, 21, 9, 13],\n",
       " [9, 20, 21, 0, 12, 7, 11, 13],\n",
       " [9, 2, 23, 1, 29, 21, 9, 13],\n",
       " [9, 2, 23, 1, 29, 13],\n",
       " [13, 20, 29, 13],\n",
       " [9, 18, 0, 1, 13, 8, 13, 18, 13],\n",
       " [9, 2, 0, 1, 29, 13],\n",
       " [5, 18, 0, 1, 21, 46, 13],\n",
       " [9, 6, 26, 1, 13],\n",
       " [9, 2, 19, 13],\n",
       " [23, 16, 1, 2, 63, 11, 13],\n",
       " [39, 6, 1, 13],\n",
       " [31, 6, 21, 31, 13],\n",
       " [17, 18, 23, 17, 13],\n",
       " [9, 2, 26, 42, 12, 21, 4, 7, 13],\n",
       " [9, 2, 44, 25, 21, 9, 13],\n",
       " [9, 10, 1, 11, 13],\n",
       " [9, 6, 0, 7, 13],\n",
       " [43, 1, 2, 15, 12, 38],\n",
       " [17, 18, 17, 13],\n",
       " [5, 20, 21, 31, 11, 13],\n",
       " [9, 18, 23, 1, 21, 13],\n",
       " [9, 2, 43, 1, 29, 13],\n",
       " [31, 2, 25, 21, 31],\n",
       " [5, 6, 26, 1, 13],\n",
       " [26, 6, 21, 1, 13],\n",
       " [5, 20, 21, 23, 7, 11, 13],\n",
       " [9, 20, 15, 12, 21, 9, 13],\n",
       " [5, 20, 11, 21, 1, 21, 31, 13],\n",
       " [2, 9, 26, 12, 34],\n",
       " [34, 6, 23, 1, 34],\n",
       " [9, 2, 38, 26, 12, 13],\n",
       " [6, 14, 4, 1, 34],\n",
       " [7, 5, 6, 39, 59, 0, 1, 13],\n",
       " [4, 7, 2, 12, 13],\n",
       " [9, 2, 12, 13],\n",
       " [23, 1, 20, 12, 1, 13],\n",
       " [9, 6, 19, 7, 13],\n",
       " [4, 7, 2, 37, 13],\n",
       " [9, 6, 31, 11, 13],\n",
       " [9, 2, 25, 21, 9, 13],\n",
       " [5, 20, 15, 12, 21, 5, 13],\n",
       " [5, 28, 5, 6, 1, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [5, 18, 21, 0, 1, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [5, 20, 15, 12, 13],\n",
       " [9, 2, 53, 13],\n",
       " [9, 18, 26, 1, 13],\n",
       " [9, 6, 0, 7, 13],\n",
       " [5, 18, 21, 31, 13],\n",
       " [5, 18, 1, 21, 17, 21, 21, 17, 13],\n",
       " [5, 6, 1, 13],\n",
       " [9, 2, 12, 13],\n",
       " [9, 6, 19, 1, 13],\n",
       " [9, 18, 9, 21, 7, 13],\n",
       " [4, 7, 6, 21, 0, 1, 13],\n",
       " [9, 18, 9, 21, 52, 19, 24, 13],\n",
       " [9, 18, 4, 1, 51, 13],\n",
       " [9, 2, 41, 13],\n",
       " [23, 1, 6, 23, 1, 13],\n",
       " [34, 2, 23, 35, 29, 34],\n",
       " [45, 9, 11, 13],\n",
       " [23, 7, 18, 23, 7, 13],\n",
       " [34, 6, 23, 7, 21, 23, 37, 17, 34],\n",
       " [6, 9, 0, 1, 34],\n",
       " [9, 2, 19, 24, 20, 29, 13],\n",
       " [5, 2, 0, 1, 29, 21, 5, 13],\n",
       " [0, 1, 2, 63, 11, 21, 23, 1, 13],\n",
       " [5, 20, 11, 21, 5, 13],\n",
       " [5, 6, 0, 15, 12, 1, 13],\n",
       " [9, 2, 2, 23, 1, 21, 63, 11, 13],\n",
       " [23, 1, 6, 21, 23, 1, 13],\n",
       " [34, 18, 23, 54, 34],\n",
       " [9, 2, 12, 21, 5, 13],\n",
       " [4, 7, 2, 21, 31, 29, 13],\n",
       " [4, 1, 2, 11, 21, 0, 1, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [2, 6, 13, 13],\n",
       " [9, 18, 9, 13],\n",
       " [23, 1, 6, 21, 13],\n",
       " [23, 1, 21, 23, 1, 20, 11, 21, 0, 12, 1, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [9, 2, 12, 21, 9, 13],\n",
       " [10, 9, 11, 34],\n",
       " [4, 1, 2, 41, 13],\n",
       " [23, 1, 6, 21, 23, 1, 13],\n",
       " [1, 6, 31, 13],\n",
       " [5, 2, 23, 1, 29, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [13, 6, 0, 1, 21, 23, 1, 13],\n",
       " [14, 1, 2, 12, 21, 16, 1, 13],\n",
       " [4, 1, 2, 4, 1, 21, 32, 29, 13],\n",
       " [1, 6, 4, 1, 13],\n",
       " [43, 2, 26, 12, 13],\n",
       " [2, 9, 1, 11, 34],\n",
       " [5, 18, 23, 7, 13],\n",
       " [23, 1, 20, 26, 12, 13],\n",
       " [4, 7, 18, 12, 13],\n",
       " [9, 2, 4, 1, 29, 13],\n",
       " [9, 2, 4, 1, 29, 13],\n",
       " [17, 18, 35, 13],\n",
       " [23, 54, 18, 13, 21, 22, 13],\n",
       " [9, 2, 4, 1, 11, 13],\n",
       " [7, 18, 23, 7, 21, 23, 7, 13],\n",
       " [9, 2, 9, 9, 44, 29, 13],\n",
       " [9, 6, 8, 9, 12, 2, 13],\n",
       " [39, 1, 2, 41, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [2, 43, 26, 12, 34],\n",
       " [9, 10, 1, 11, 13],\n",
       " [4, 7, 2, 12, 13],\n",
       " [23, 7, 2, 29, 38],\n",
       " [5, 2, 19, 24, 12, 13],\n",
       " [23, 1, 13, 35, 13, 20, 11, 21, 5, 13],\n",
       " [23, 35, 18, 21, 22, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [31, 6, 21, 44, 1, 28, 19, 1, 13],\n",
       " [5, 18, 21, 21, 4, 12, 1, 13],\n",
       " [4, 1, 6, 61, 9, 49, 4, 1, 6, 13],\n",
       " [9, 6, 39, 1, 21, 31, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [23, 1, 17, 6, 21, 31, 13],\n",
       " [23, 1, 13, 35, 13, 20, 11, 21, 5, 13],\n",
       " [31, 20, 44, 1, 29, 13],\n",
       " [39, 1, 11, 1, 21, 13],\n",
       " [9, 20, 12, 21, 23, 1, 13],\n",
       " [9, 6, 21, 53, 21, 53, 13],\n",
       " [9, 6, 0, 7, 21, 23, 1, 51, 13],\n",
       " [23, 1, 2, 26, 12, 13],\n",
       " [9, 2, 25, 21, 4, 7, 13],\n",
       " [9, 6, 4, 1, 13],\n",
       " [4, 1, 2, 41, 13],\n",
       " [4, 1, 2, 19, 24, 16, 13],\n",
       " [9, 2, 29, 13],\n",
       " [9, 2, 12, 13],\n",
       " [9, 6, 25, 19, 1, 13],\n",
       " [26, 2, 12, 13],\n",
       " [39, 18, 9, 21, 13],\n",
       " [23, 1, 2, 19, 1, 29, 13],\n",
       " [9, 6, 1, 21, 1, 28, 1, 13],\n",
       " [26, 6, 21, 1, 13],\n",
       " [9, 2, 2, 26, 12, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [5, 18, 0, 1, 21, 31, 13],\n",
       " [23, 50, 1, 6, 21, 21, 23, 50, 13],\n",
       " [13, 18, 21, 59, 21, 59, 13],\n",
       " [9, 20, 38, 26, 12, 13],\n",
       " [13, 6, 19, 1, 21, 31, 13],\n",
       " [9, 45, 23, 1, 11, 13],\n",
       " [9, 18, 0, 1, 21, 23, 1, 13],\n",
       " [23, 1, 36, 2, 11, 13],\n",
       " [5, 6, 1, 13],\n",
       " [5, 18, 13],\n",
       " [13, 6, 1, 21, 23, 1, 13],\n",
       " [6, 1, 34],\n",
       " [34, 2, 5, 12, 21, 34],\n",
       " [34, 2, 35, 29, 34],\n",
       " [9, 6, 5, 13, 8, 9, 12, 2, 13],\n",
       " [43, 1, 2, 41, 13],\n",
       " [5, 18, 21, 23, 41, 1, 13],\n",
       " [9, 6, 26, 1, 13],\n",
       " [21, 34, 1, 6, 23, 7, 5, 34],\n",
       " [9, 6, 23, 1, 21, 19, 24, 13],\n",
       " [9, 6, 15, 12, 1, 13],\n",
       " [9, 2, 0, 1, 21, 5, 29, 13],\n",
       " [9, 2, 19, 1, 29, 13],\n",
       " [6, 9, 21, 12, 1, 34],\n",
       " [9, 18, 0, 1, 21, 23, 1],\n",
       " [9, 20, 15, 12, 21, 9, 14, 16, 1, 18, 13],\n",
       " [9, 2, 12, 13],\n",
       " [23, 1, 18, 21, 4, 1, 13],\n",
       " [9, 2, 23, 1, 21, 19, 24, 29, 13],\n",
       " [9, 18, 0, 7, 13],\n",
       " [5, 6, 4, 1, 21, 13],\n",
       " [9, 6, 19, 24, 13],\n",
       " [5, 20, 12, 21, 5, 13],\n",
       " [5, 18, 23, 1, 21, 13],\n",
       " [9, 6, 9, 8, 9, 12, 2, 13],\n",
       " [23, 1, 6, 19, 24, 13],\n",
       " [12, 1, 21, 23, 1, 2, 12, 13],\n",
       " [23, 7, 18, 21, 37, 1, 13],\n",
       " [4, 1, 6, 21, 0, 1, 13],\n",
       " [9, 2, 16, 39, 12, 13],\n",
       " [9, 6, 21, 1, 21, 5, 13],\n",
       " [4, 7, 2, 0, 44, 12, 13],\n",
       " [9, 2, 12, 13],\n",
       " [4, 7, 2, 19, 24, 25, 21, 9, 13, 27, 9, 2, 19, 24, 25, 13],\n",
       " [34, 6, 23, 37, 7, 34],\n",
       " [9, 18, 0, 19, 1, 13],\n",
       " [9, 2, 0, 1, 29, 13],\n",
       " [23, 54, 18, 21, 22, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [13, 6, 13],\n",
       " [9, 2, 44, 25, 21, 9, 13],\n",
       " [9, 18, 21, 21, 43, 1, 13],\n",
       " [34, 1, 2, 5, 21, 5, 28, 5, 29, 34],\n",
       " [9, 45, 23, 1, 11, 38],\n",
       " [5, 18, 23, 1, 13],\n",
       " [23, 1, 20, 15, 12, 13],\n",
       " [10, 2, 9, 29, 13],\n",
       " [39, 1, 11, 13],\n",
       " [5, 20, 11, 21, 1, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [2, 9, 12, 34],\n",
       " [5, 6, 0, 7, 13],\n",
       " [4, 1, 6, 21, 4, 1, 13],\n",
       " [5, 2, 23, 1, 29, 13],\n",
       " [9, 18, 26, 13],\n",
       " [9, 2, 0, 1, 29, 13],\n",
       " [5, 6, 0, 1, 13],\n",
       " [5, 18, 0, 1, 13],\n",
       " [9, 20, 63, 11, 13],\n",
       " [5, 18, 21, 22, 13],\n",
       " [23, 1, 6, 13, 51, 13, 13],\n",
       " [23, 1, 18, 19, 24, 13],\n",
       " [9, 18, 57, 19, 24, 13],\n",
       " [9, 18, 21, 23, 1, 21, 0, 1, 13],\n",
       " [39, 1, 39, 9, 18, 18, 9, 13],\n",
       " [9, 18, 0, 1, 21, 0, 1, 13],\n",
       " [5, 6, 26, 1, 13],\n",
       " [43, 1, 2, 12, 13],\n",
       " [21, 34, 37, 1, 6, 23, 35, 34],\n",
       " [9, 2, 25, 21, 9, 13],\n",
       " [9, 2, 12, 21, 5, 4, 7, 13],\n",
       " [9, 2, 44, 1, 21, 31, 29, 13],\n",
       " [5, 2, 9, 29, 13],\n",
       " [9, 6, 2, 31, 13],\n",
       " [9, 2, 12, 21, 23, 1, 13],\n",
       " [34, 6, 7, 21, 17, 34],\n",
       " [34, 1, 6, 5, 34],\n",
       " [5, 2, 12, 21, 1, 13],\n",
       " [5, 6, 1, 13],\n",
       " [23, 1, 6, 21, 21, 23, 50, 13],\n",
       " [23, 1, 21, 23, 50, 20, 11, 21, 1, 13],\n",
       " [9, 2, 23, 1, 21, 23, 7, 29, 13],\n",
       " [13, 6, 1, 21, 23, 1, 13],\n",
       " [4, 7, 6, 26, 1, 13],\n",
       " [5, 18, 19, 24, 20, 13],\n",
       " [34, 1, 6, 9, 34],\n",
       " [9, 6, 21, 1, 13],\n",
       " [19, 24, 2, 12, 21, 19, 24, 13],\n",
       " [5, 18, 5, 21, 23, 1, 13],\n",
       " [9, 2, 12, 21, 1, 13],\n",
       " [9, 20, 53, 13],\n",
       " [5, 18, 21, 17, 13],\n",
       " [5, 6, 0, 7, 13],\n",
       " [9, 18, 9, 19, 24, 13],\n",
       " [9, 20, 3, 21, 23, 1, 13],\n",
       " [34, 20, 5, 11, 34],\n",
       " [23, 1, 18, 21, 21, 31, 13],\n",
       " [9, 36, 21, 53, 11, 13],\n",
       " [23, 1, 2, 12, 13],\n",
       " [9, 2, 53, 13],\n",
       " [5, 6, 21, 23, 1, 21, 23, 1, 13],\n",
       " [5, 2, 12, 13],\n",
       " [1, 2, 15, 12, 21, 31, 13],\n",
       " [9, 18, 23, 1, 21, 9, 31, 18, 13],\n",
       " [4, 7, 6, 21, 0, 1, 13],\n",
       " [9, 2, 49, 29, 13],\n",
       " [9, 20, 11, 21, 23, 1, 21, 19, 12, 1, 13],\n",
       " [7, 5, 2, 15, 12, 21, 1, 13],\n",
       " [9, 2, 26, 25, 21, 9, 13],\n",
       " [17, 18, 21, 22, 0, 19, 24, 13],\n",
       " [45, 9, 4, 1, 11, 34],\n",
       " [9, 2, 12, 13],\n",
       " [9, 18, 23, 1, 13],\n",
       " [10, 20, 9, 12, 13],\n",
       " [9, 20, 11, 33, 11, 13],\n",
       " [23, 1, 6, 13],\n",
       " [4, 1, 6, 49, 1, 13],\n",
       " [23, 7, 20, 21, 7, 11, 13],\n",
       " [9, 18, 9, 38],\n",
       " [5, 18, 5, 13],\n",
       " [23, 1, 6, 21, 23, 1, 21, 23, 1, 13],\n",
       " [43, 1, 18, 0, 1, 21, 23, 1, 13],\n",
       " [14, 2, 0, 19, 24, 12, 13],\n",
       " [23, 1, 6, 21, 21, 23, 50, 13],\n",
       " [9, 2, 23, 1, 41, 29, 13],\n",
       " [5, 18, 4, 1, 13],\n",
       " [43, 1, 6, 13],\n",
       " [5, 18, 21, 35, 13],\n",
       " [9, 18, 23, 1, 21, 4, 1, 21, 13],\n",
       " [39, 1, 11, 0, 12, 1, 13],\n",
       " [34, 18, 5, 34],\n",
       " [9, 2, 29, 13],\n",
       " [5, 18, 23, 1, 21, 5, 13],\n",
       " [4, 7, 6, 21, 0, 1, 13],\n",
       " [5, 2, 26, 1, 63, 11, 13],\n",
       " [7, 5, 20, 11, 21, 31, 13],\n",
       " [9, 18, 9, 21, 53, 13],\n",
       " [9, 6, 0, 7, 13],\n",
       " [23, 1, 62, 9, 21, 53, 13],\n",
       " [34, 1, 6, 0, 21, 23, 31, 34],\n",
       " [7, 5, 18, 21, 22, 13],\n",
       " [34, 6, 43, 1, 34],\n",
       " [5, 2, 25, 19, 1, 29, 13],\n",
       " [4, 7, 2, 12, 13, 27, 4, 7, 2, 12, 13],\n",
       " [9, 2, 12, 21, 9, 13],\n",
       " [9, 2, 12, 21, 4, 7, 13],\n",
       " [13, 6, 0, 12, 1, 21, 50, 13],\n",
       " [34, 18, 13, 35, 13, 34],\n",
       " [21, 34, 1, 18, 5, 34],\n",
       " [23, 1, 18, 21, 23, 1, 21, 31, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [5, 18, 4, 1, 51, 13],\n",
       " [9, 18, 1, 21, 4, 1, 33, 18, 9, 13],\n",
       " [43, 6, 0, 12, 1, 13],\n",
       " [23, 19, 1, 18, 21, 23, 1, 13],\n",
       " [9, 2, 19, 24, 25, 21, 9, 13],\n",
       " [23, 7, 18, 23, 1, 13],\n",
       " [23, 7, 2, 23, 12, 1, 29, 13],\n",
       " [23, 1, 20, 12, 13],\n",
       " [43, 6, 0, 12, 1, 13],\n",
       " [23, 1, 2, 12, 7, 13],\n",
       " [5, 18, 5, 23, 1, 13],\n",
       " [34, 6, 14, 12, 1, 34],\n",
       " [17, 2, 11, 21, 17, 13],\n",
       " [7, 5, 6, 19, 1, 13],\n",
       " [4, 7, 2, 12, 13],\n",
       " [9, 2, 25, 21, 4, 7, 13],\n",
       " [9, 2, 44, 25, 21, 9, 13],\n",
       " [5, 18, 4, 1, 13],\n",
       " [23, 1, 21, 23, 1, 6, 1, 13],\n",
       " [9, 2, 12, 21, 9, 13],\n",
       " [9, 6, 19, 7, 13],\n",
       " [9, 6, 9, 13],\n",
       " [9, 6, 1, 13],\n",
       " [13, 6, 0, 1, 21, 23, 1, 13],\n",
       " [5, 18, 0, 44, 1, 13],\n",
       " [5, 18, 21, 47, 13],\n",
       " [34, 7, 6, 31, 34],\n",
       " [34, 18, 5, 34],\n",
       " [13, 6, 21, 23, 1, 21, 43, 1, 13],\n",
       " [4, 1, 20, 11, 13],\n",
       " [17, 18, 17, 13],\n",
       " [9, 45, 9, 11, 13],\n",
       " [23, 1, 6, 21, 53, 13],\n",
       " [9, 42, 5, 13],\n",
       " [0, 7, 18, 7, 5, 13],\n",
       " [5, 18, 46, 21, 13],\n",
       " [9, 18, 1, 13],\n",
       " [9, 2, 12, 13],\n",
       " [5, 2, 12, 13],\n",
       " [9, 18, 9, 13],\n",
       " [9, 2, 12, 13],\n",
       " [9, 2, 25, 21, 9, 13],\n",
       " [5, 18, 0, 7, 13],\n",
       " [9, 2, 25, 21, 9, 13],\n",
       " [9, 18, 0, 1, 13],\n",
       " [5, 18, 21, 5, 13],\n",
       " [5, 20, 11, 21, 31, 13],\n",
       " [17, 6, 0, 37, 1, 13],\n",
       " [4, 1, 20, 11, 13],\n",
       " [34, 2, 23, 1, 29, 34],\n",
       " [23, 1, 39, 9, 29, 2, 2, 12, 13],\n",
       " [7, 5, 6, 21, 0, 1, 13],\n",
       " [9, 18, 57, 19, 24, 13],\n",
       " [14, 1, 2, 19, 24, 25, 13],\n",
       " [9, 20, 19, 24, 11, 13],\n",
       " [43, 6, 4, 1, 13],\n",
       " [34, 6, 4, 1, 34],\n",
       " [9, 6, 5, 13, 51, 13, 13],\n",
       " [9, 18, 0, 1, 21, 23, 1, 13],\n",
       " [9, 45, 23, 1, 26, 49, 11, 13],\n",
       " [9, 2, 12, 21, 4, 7, 13],\n",
       " [9, 6, 21, 9, 21, 31, 13],\n",
       " [34, 11, 23, 1, 21, 19, 34],\n",
       " [9, 6, 52, 19, 1, 13],\n",
       " [6, 9, 21, 31, 34],\n",
       " [34, 6, 23, 7, 21, 23, 1, 34],\n",
       " [9, 18, 21, 23, 1, 13],\n",
       " [39, 1, 26, 5, 18, 13],\n",
       " [9, 2, 53, 13],\n",
       " [23, 1, 21, 31, 20, 12, 21, 9, 13],\n",
       " [5, 18, 0, 1, 21, 31, 21, 4, 7, 13],\n",
       " [23, 1, 2, 19, 24, 16, 13],\n",
       " [7, 5, 18, 23, 1, 13],\n",
       " [5, 18, 5, 21, 13],\n",
       " [5, 18, 21, 17, 13],\n",
       " [9, 2, 21, 23, 7, 38, 29, 13],\n",
       " [1, 6, 21, 1, 21, 1, 13],\n",
       " [9, 18, 21, 23, 12, 1, 13],\n",
       " [19, 1, 19, 11, 19, 13],\n",
       " [9, 20, 11, 21, 0, 1, 13],\n",
       " [9, 2, 63, 11, 13],\n",
       " [9, 6, 39, 1, 1, 13],\n",
       " [34, 2, 1, 29, 34],\n",
       " [9, 2, 29, 21, 0, 7, 13],\n",
       " [43, 1, 2, 26, 25, 21, 0, 1, 13],\n",
       " [17, 2, 11, 21, 31, 13],\n",
       " [23, 1, 18, 19, 24, 13],\n",
       " [14, 1, 18, 9, 12, 13],\n",
       " [9, 18, 21, 23, 1, 13],\n",
       " [5, 18, 23, 1, 13],\n",
       " [34, 18, 23, 1, 21, 23, 7, 21, 5, 34]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "583dd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = metric.compute(predictions=all_prediction_labels, references=all_true_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b21a7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6129032258064516,\n",
       "  'recall': 0.3064516129032258,\n",
       "  'f1': 0.4086021505376344,\n",
       "  'number': 62},\n",
       " '1': {'precision': 0.32132963988919666,\n",
       "  'recall': 0.3717948717948718,\n",
       "  'f1': 0.3447251114413076,\n",
       "  'number': 312},\n",
       " '2': {'precision': 0.5740740740740741,\n",
       "  'recall': 0.2540983606557377,\n",
       "  'f1': 0.35227272727272724,\n",
       "  'number': 122},\n",
       " '3': {'precision': 0.8928571428571429,\n",
       "  'recall': 0.76103500761035,\n",
       "  'f1': 0.8216926869350862,\n",
       "  'number': 657},\n",
       " '4': {'precision': 0.8586956521739131,\n",
       "  'recall': 0.626984126984127,\n",
       "  'f1': 0.7247706422018348,\n",
       "  'number': 126},\n",
       " '5': {'precision': 0.07407407407407407,\n",
       "  'recall': 0.03773584905660377,\n",
       "  'f1': 0.05,\n",
       "  'number': 53},\n",
       " '6': {'precision': 0.7674418604651163,\n",
       "  'recall': 0.66,\n",
       "  'f1': 0.7096774193548386,\n",
       "  'number': 50},\n",
       " '7': {'precision': 0.18823529411764706,\n",
       "  'recall': 0.4444444444444444,\n",
       "  'f1': 0.2644628099173554,\n",
       "  'number': 36},\n",
       " '8': {'precision': 0.3225806451612903,\n",
       "  'recall': 0.4166666666666667,\n",
       "  'f1': 0.3636363636363636,\n",
       "  'number': 144},\n",
       " '9': {'precision': 0.3577981651376147,\n",
       "  'recall': 0.312,\n",
       "  'f1': 0.33333333333333337,\n",
       "  'number': 125},\n",
       " '_': {'precision': 0.5652173913043478,\n",
       "  'recall': 0.5490683229813664,\n",
       "  'f1': 0.5570258349086326,\n",
       "  'number': 805},\n",
       " 'overall_precision': 0.5738197424892704,\n",
       " 'overall_recall': 0.5365168539325843,\n",
       " 'overall_f1': 0.554541683948569,\n",
       " 'overall_accuracy': 0.5619483491337038}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d619101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

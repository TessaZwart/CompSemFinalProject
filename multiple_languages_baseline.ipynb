{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89512d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import tnt\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba84b7",
   "metadata": {},
   "source": [
    "# READ IN AND MERGE ALL  DATA SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df9aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The English training data set has 7745 sentences.\n",
      "The German training data set has 1740 sentences.\n",
      "The Dutch training data set has 538 sentences.\n",
      "The Italian training data set has 684 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('train.en.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_en = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data_en.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "\n",
    "print(\"The English training data set has\",len(train_data_en), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.de.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_de = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data_de.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The German training data set has\",len(train_data_de), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_nl = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data_nl.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The Dutch training data set has\",len(train_data_nl), \"sentences.\" )\n",
    "\n",
    "full_sen = []\n",
    "with open('train.it.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break    \n",
    "\n",
    "tokens = []\n",
    "tags = []\n",
    "train_tags = []\n",
    "train_token =[]\n",
    "train_data_it = []\n",
    "train =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            train_token.append(tokens) \n",
    "            tokens = []\n",
    "            train_tags.append(tags)\n",
    "            tags = []\n",
    "            train_data_it.append(train)\n",
    "            train = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            train.append((string[0],string[3]))\n",
    "            \n",
    "print(\"The Italian training data set has\",len(train_data_it), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f2fd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10707"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data = train_data_en + train_data_de + train_data_nl + train_data_it\n",
    "len(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd52f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(whole_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c16d7e",
   "metadata": {},
   "source": [
    "## PREDICT ON DUTCH DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e46990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing data set has 490 sentences.\n"
     ]
    }
   ],
   "source": [
    "full_sen = []\n",
    "with open('test.nl.txt') as fh:\n",
    "    # Skip initial comments that starts with #\n",
    "    while True:\n",
    "        line = fh.readline()\n",
    "        # break while statement if it is not a comment line\n",
    "        # i.e. does not startwith #\n",
    "        if not line.startswith('#'):\n",
    "            full_sen.append(line) \n",
    "        if not line:\n",
    "            break   \n",
    "tokens = []\n",
    "tags = []\n",
    "test_token = []\n",
    "test_tags =[]\n",
    "test_data = []\n",
    "test =[]\n",
    "for i in range (0, len(full_sen)):\n",
    "    string = full_sen[i].split(\"\\t\")\n",
    "    if not len(full_sen[i]) == 0: \n",
    "        if string[0] == '\\n':\n",
    "            test_token.append(tokens) \n",
    "            tokens = []\n",
    "            test_tags.append(tags)\n",
    "            tags = []\n",
    "            test_data.append(train)\n",
    "            test = []\n",
    "        else:\n",
    "            tokens.append(string[0])\n",
    "            tags.append(string[3])\n",
    "            test.append((string[0],string[3]))\n",
    "\n",
    "print(\"The testing data set has\",len(test_data), \"sentences.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c60caa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2294 out of 3059 semantic tags are correct.\n",
      "We have a accuracy of 0.7499182739457338\n"
     ]
    }
   ],
   "source": [
    "# initializing tagger\n",
    "tnt_tagging = tnt.TnT()\n",
    "# training\n",
    "tnt_tagging.train(whole_data)\n",
    "# evaluating\n",
    "prediction = tnt_tagging.tagdata(test_token)\n",
    "\n",
    "# get the list of predictions \n",
    "tag_pred = []\n",
    "for i in range(0,len(prediction)):\n",
    "    for j in range (0, len(prediction[i])):\n",
    "        tag_pred.append(prediction[i][j][1])\n",
    "        \n",
    "# get the list of real tags\n",
    "tag_real = []\n",
    "for i in range(0, len(test_tags)):\n",
    "    for j in range(0,len(test_tags[i])):\n",
    "        tag_real.append(test_tags[i][j])\n",
    "\n",
    "#Compare and compute accuracy\n",
    "correct = 0\n",
    "for i in range(0,len(tag_real)):\n",
    "    if tag_real[i] == tag_pred[i]:\n",
    "        correct+=1\n",
    "print(correct, \"out of\", len(tag_real), \"semantic tags are correct.\")\n",
    "print(\"We have a accuracy of\", (correct/len(tag_real)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
